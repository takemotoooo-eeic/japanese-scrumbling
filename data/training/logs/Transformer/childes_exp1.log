2025-10-20 19:39:27.942 | INFO     | __main__:<module>:82 - Loading data
2025-10-20 19:39:27.942 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-20 19:39:27.949 | INFO     | corpus:__init__:86 - Loaded dictionary from data/CHILDES/train_dict_a7be993a.cached
2025-10-20 19:39:27.949 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/train.txt.original...
2025-10-20 19:39:27.959 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/valid.txt.original...
2025-10-20 19:39:27.960 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/test.txt.original...
2025-10-20 19:39:27.961 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-20 19:39:27.961 | INFO     | __main__:<module>:88 - ( 0.02 )
2025-10-20 19:39:27.961 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-20 19:39:27.961 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-20 19:39:27.964 | INFO     | __main__:<module>:128 - Building the model
2025-10-20 19:39:28.003 | INFO     | __main__:<module>:315 - Running Transformer with args: {'data': 'data/CHILDES', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': False, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-20 19:39:28.003 | INFO     | __main__:<module>:317 - Transformer id: 13f9229b
2025-10-20 19:39:37.252 | INFO     | __main__:train:295 - | epoch   0 |   200/ 1632 batches | lr 20.00 | ms/batch 46.24 | loss  9.27 | ppl 10628.84
2025-10-20 19:39:46.207 | INFO     | __main__:train:295 - | epoch   0 |   400/ 1632 batches | lr 20.00 | ms/batch 44.77 | loss  8.17 | ppl  3518.82
2025-10-20 19:39:55.053 | INFO     | __main__:train:295 - | epoch   0 |   600/ 1632 batches | lr 20.00 | ms/batch 44.23 | loss  7.80 | ppl  2443.47
2025-10-20 19:39:56.127 | INFO     | __main__:<module>:378 - -----------------------------------------------------------------------------------------
2025-10-20 19:39:56.127 | INFO     | __main__:<module>:379 - Exiting from training early
2025-10-20 19:40:58.592 | INFO     | __main__:<module>:76 - Using GPU ID 0
2025-10-20 19:40:58.693 | INFO     | __main__:<module>:82 - Loading data
2025-10-20 19:40:58.693 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-20 19:40:58.700 | INFO     | corpus:__init__:86 - Loaded dictionary from data/CHILDES/train_dict_a7be993a.cached
2025-10-20 19:40:58.700 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/train.txt.original...
2025-10-20 19:40:58.710 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/valid.txt.original...
2025-10-20 19:40:58.711 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/test.txt.original...
2025-10-20 19:40:58.712 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-20 19:40:58.712 | INFO     | __main__:<module>:88 - ( 0.02 )
2025-10-20 19:40:58.712 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-20 19:40:58.712 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-20 19:40:58.715 | INFO     | __main__:<module>:128 - Building the model
2025-10-20 19:40:58.757 | INFO     | __main__:<module>:315 - Running Transformer with args: {'data': 'data/CHILDES', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': True, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-20 19:40:58.757 | INFO     | __main__:<module>:317 - Transformer id: d25ef8a2
2025-10-20 19:40:59.275 | INFO     | __main__:train:295 - | epoch   0 |   200/ 1632 batches | lr 20.00 | ms/batch  2.59 | loss  9.53 | ppl 13721.91
2025-10-20 19:40:59.675 | INFO     | __main__:train:295 - | epoch   0 |   400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  8.21 | ppl  3670.09
2025-10-20 19:41:00.076 | INFO     | __main__:train:295 - | epoch   0 |   600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  8.03 | ppl  3058.05
2025-10-20 19:41:00.476 | INFO     | __main__:train:295 - | epoch   0 |   800/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.81 | ppl  2459.30
2025-10-20 19:41:00.874 | INFO     | __main__:train:295 - | epoch   0 |  1000/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.65 | ppl  2092.66
2025-10-20 19:41:01.276 | INFO     | __main__:train:295 - | epoch   0 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  7.74 | ppl  2292.08
2025-10-20 19:41:01.674 | INFO     | __main__:train:295 - | epoch   0 |  1400/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.55 | ppl  1900.79
2025-10-20 19:41:02.075 | INFO     | __main__:train:295 - | epoch   0 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.02 | ppl  1123.65
2025-10-20 19:41:02.317 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:02.317 | INFO     | __main__:<module>:344 - | end of epoch   0 | time:  3.56s | valid loss  6.30 | valid ppl   545.00
2025-10-20 19:41:02.382 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:02.802 | INFO     | __main__:train:295 - | epoch   1 |   200/ 1632 batches | lr 20.00 | ms/batch  2.10 | loss  7.09 | ppl  1201.60
2025-10-20 19:41:03.202 | INFO     | __main__:train:295 - | epoch   1 |   400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.00 | ppl  1095.12
2025-10-20 19:41:03.602 | INFO     | __main__:train:295 - | epoch   1 |   600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.07 | ppl  1171.49
2025-10-20 19:41:04.002 | INFO     | __main__:train:295 - | epoch   1 |   800/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.10 | ppl  1207.71
2025-10-20 19:41:04.402 | INFO     | __main__:train:295 - | epoch   1 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.01 | ppl  1102.57
2025-10-20 19:41:04.802 | INFO     | __main__:train:295 - | epoch   1 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.92 | ppl  1015.40
2025-10-20 19:41:05.202 | INFO     | __main__:train:295 - | epoch   1 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.81 | ppl   911.04
2025-10-20 19:41:05.602 | INFO     | __main__:train:295 - | epoch   1 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.96 | ppl  1053.74
2025-10-20 19:41:05.839 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:05.839 | INFO     | __main__:<module>:344 - | end of epoch   1 | time:  3.46s | valid loss  5.92 | valid ppl   371.19
2025-10-20 19:41:05.902 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:06.308 | INFO     | __main__:train:295 - | epoch   2 |   200/ 1632 batches | lr 20.00 | ms/batch  2.03 | loss  6.99 | ppl  1084.70
2025-10-20 19:41:06.708 | INFO     | __main__:train:295 - | epoch   2 |   400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.91 | ppl  1006.85
2025-10-20 19:41:07.108 | INFO     | __main__:train:295 - | epoch   2 |   600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.85 | ppl   946.54
2025-10-20 19:41:07.508 | INFO     | __main__:train:295 - | epoch   2 |   800/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.98 | ppl  1074.74
2025-10-20 19:41:07.908 | INFO     | __main__:train:295 - | epoch   2 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.89 | ppl   984.51
2025-10-20 19:41:08.308 | INFO     | __main__:train:295 - | epoch   2 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.86 | ppl   956.55
2025-10-20 19:41:08.714 | INFO     | __main__:train:295 - | epoch   2 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.03 | loss  6.89 | ppl   978.70
2025-10-20 19:41:09.117 | INFO     | __main__:train:295 - | epoch   2 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  6.99 | ppl  1082.21
2025-10-20 19:41:09.357 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:09.357 | INFO     | __main__:<module>:344 - | end of epoch   2 | time:  3.46s | valid loss  6.67 | valid ppl   789.00
2025-10-20 19:41:09.357 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:41:09.357 | INFO     | __main__:<module>:368 - | reducing learning rate to 5.0
2025-10-20 19:41:09.393 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:09.816 | INFO     | __main__:train:295 - | epoch   3 |   200/ 1632 batches | lr 5.00 | ms/batch  2.12 | loss  5.73 | ppl   308.75
2025-10-20 19:41:10.232 | INFO     | __main__:train:295 - | epoch   3 |   400/ 1632 batches | lr 5.00 | ms/batch  2.08 | loss  5.70 | ppl   299.72
2025-10-20 19:41:10.634 | INFO     | __main__:train:295 - | epoch   3 |   600/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.70 | ppl   298.24
2025-10-20 19:41:11.037 | INFO     | __main__:train:295 - | epoch   3 |   800/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.70 | ppl   297.70
2025-10-20 19:41:11.439 | INFO     | __main__:train:295 - | epoch   3 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.70 | ppl   299.23
2025-10-20 19:41:11.840 | INFO     | __main__:train:295 - | epoch   3 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.69 | ppl   297.13
2025-10-20 19:41:12.242 | INFO     | __main__:train:295 - | epoch   3 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.68 | ppl   294.07
2025-10-20 19:41:12.645 | INFO     | __main__:train:295 - | epoch   3 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.69 | ppl   295.90
2025-10-20 19:41:12.885 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:12.886 | INFO     | __main__:<module>:344 - | end of epoch   3 | time:  3.49s | valid loss  5.73 | valid ppl   307.07
2025-10-20 19:41:12.947 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:13.354 | INFO     | __main__:train:295 - | epoch   4 |   200/ 1632 batches | lr 5.00 | ms/batch  2.04 | loss  5.71 | ppl   301.76
2025-10-20 19:41:13.756 | INFO     | __main__:train:295 - | epoch   4 |   400/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.69 | ppl   294.53
2025-10-20 19:41:14.158 | INFO     | __main__:train:295 - | epoch   4 |   600/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.68 | ppl   293.18
2025-10-20 19:41:14.559 | INFO     | __main__:train:295 - | epoch   4 |   800/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   293.29
2025-10-20 19:41:14.960 | INFO     | __main__:train:295 - | epoch   4 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.69 | ppl   295.45
2025-10-20 19:41:15.373 | INFO     | __main__:train:295 - | epoch   4 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.06 | loss  5.68 | ppl   293.30
2025-10-20 19:41:15.778 | INFO     | __main__:train:295 - | epoch   4 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.03 | loss  5.67 | ppl   290.39
2025-10-20 19:41:16.179 | INFO     | __main__:train:295 - | epoch   4 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   292.33
2025-10-20 19:41:16.423 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:16.423 | INFO     | __main__:<module>:344 - | end of epoch   4 | time:  3.48s | valid loss  5.73 | valid ppl   307.86
2025-10-20 19:41:16.423 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:41:16.423 | INFO     | __main__:<module>:368 - | reducing learning rate to 1.25
2025-10-20 19:41:16.470 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:16.892 | INFO     | __main__:train:295 - | epoch   5 |   200/ 1632 batches | lr 1.25 | ms/batch  2.11 | loss  5.69 | ppl   295.10
2025-10-20 19:41:17.294 | INFO     | __main__:train:295 - | epoch   5 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.19
2025-10-20 19:41:17.695 | INFO     | __main__:train:295 - | epoch   5 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   287.49
2025-10-20 19:41:18.096 | INFO     | __main__:train:295 - | epoch   5 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.16
2025-10-20 19:41:18.496 | INFO     | __main__:train:295 - | epoch   5 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.67 | ppl   289.05
2025-10-20 19:41:18.898 | INFO     | __main__:train:295 - | epoch   5 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.85
2025-10-20 19:41:19.360 | INFO     | __main__:train:295 - | epoch   5 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.31 | loss  5.65 | ppl   285.64
2025-10-20 19:41:19.762 | INFO     | __main__:train:295 - | epoch   5 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.73
2025-10-20 19:41:20.013 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:20.014 | INFO     | __main__:<module>:344 - | end of epoch   5 | time:  3.54s | valid loss  5.66 | valid ppl   287.64
2025-10-20 19:41:20.072 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:20.482 | INFO     | __main__:train:295 - | epoch   6 |   200/ 1632 batches | lr 1.25 | ms/batch  2.05 | loss  5.68 | ppl   293.54
2025-10-20 19:41:20.884 | INFO     | __main__:train:295 - | epoch   6 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.13
2025-10-20 19:41:21.284 | INFO     | __main__:train:295 - | epoch   6 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.69
2025-10-20 19:41:21.686 | INFO     | __main__:train:295 - | epoch   6 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.41
2025-10-20 19:41:22.086 | INFO     | __main__:train:295 - | epoch   6 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   288.31
2025-10-20 19:41:22.488 | INFO     | __main__:train:295 - | epoch   6 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.27
2025-10-20 19:41:22.889 | INFO     | __main__:train:295 - | epoch   6 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.02
2025-10-20 19:41:23.296 | INFO     | __main__:train:295 - | epoch   6 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.66 | ppl   286.26
2025-10-20 19:41:23.541 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:23.541 | INFO     | __main__:<module>:344 - | end of epoch   6 | time:  3.47s | valid loss  5.66 | valid ppl   285.98
2025-10-20 19:41:23.606 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:24.014 | INFO     | __main__:train:295 - | epoch   7 |   200/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.68 | ppl   292.85
2025-10-20 19:41:24.416 | INFO     | __main__:train:295 - | epoch   7 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.73
2025-10-20 19:41:24.818 | INFO     | __main__:train:295 - | epoch   7 |   600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.11
2025-10-20 19:41:25.220 | INFO     | __main__:train:295 - | epoch   7 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   285.93
2025-10-20 19:41:25.621 | INFO     | __main__:train:295 - | epoch   7 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.80
2025-10-20 19:41:26.022 | INFO     | __main__:train:295 - | epoch   7 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.78
2025-10-20 19:41:26.424 | INFO     | __main__:train:295 - | epoch   7 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   284.70
2025-10-20 19:41:26.836 | INFO     | __main__:train:295 - | epoch   7 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.66 | ppl   285.89
2025-10-20 19:41:27.079 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:27.079 | INFO     | __main__:<module>:344 - | end of epoch   7 | time:  3.47s | valid loss  5.66 | valid ppl   287.31
2025-10-20 19:41:27.079 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:41:27.079 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.3125
2025-10-20 19:41:27.112 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:27.528 | INFO     | __main__:train:295 - | epoch   8 |   200/ 1632 batches | lr 0.31 | ms/batch  2.08 | loss  5.68 | ppl   292.43
2025-10-20 19:41:27.930 | INFO     | __main__:train:295 - | epoch   8 |   400/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.66 | ppl   286.20
2025-10-20 19:41:28.332 | INFO     | __main__:train:295 - | epoch   8 |   600/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   285.54
2025-10-20 19:41:28.732 | INFO     | __main__:train:295 - | epoch   8 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.36
2025-10-20 19:41:29.134 | INFO     | __main__:train:295 - | epoch   8 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.66 | ppl   287.19
2025-10-20 19:41:29.536 | INFO     | __main__:train:295 - | epoch   8 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.66 | ppl   286.03
2025-10-20 19:41:29.945 | INFO     | __main__:train:295 - | epoch   8 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.65 | ppl   283.96
2025-10-20 19:41:30.346 | INFO     | __main__:train:295 - | epoch   8 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.03
2025-10-20 19:41:30.588 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:30.588 | INFO     | __main__:<module>:344 - | end of epoch   8 | time:  3.48s | valid loss  5.65 | valid ppl   285.23
2025-10-20 19:41:30.659 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:31.070 | INFO     | __main__:train:295 - | epoch   9 |   200/ 1632 batches | lr 0.31 | ms/batch  2.05 | loss  5.68 | ppl   291.91
2025-10-20 19:41:31.474 | INFO     | __main__:train:295 - | epoch   9 |   400/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.66 | ppl   285.93
2025-10-20 19:41:31.876 | INFO     | __main__:train:295 - | epoch   9 |   600/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   285.37
2025-10-20 19:41:32.276 | INFO     | __main__:train:295 - | epoch   9 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.09
2025-10-20 19:41:32.676 | INFO     | __main__:train:295 - | epoch   9 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.93
2025-10-20 19:41:33.076 | INFO     | __main__:train:295 - | epoch   9 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   285.99
2025-10-20 19:41:33.476 | INFO     | __main__:train:295 - | epoch   9 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.85
2025-10-20 19:41:33.876 | INFO     | __main__:train:295 - | epoch   9 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.87
2025-10-20 19:41:34.117 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:34.117 | INFO     | __main__:<module>:344 - | end of epoch   9 | time:  3.46s | valid loss  5.65 | valid ppl   285.28
2025-10-20 19:41:34.117 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:41:34.117 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.078125
2025-10-20 19:41:34.149 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:34.560 | INFO     | __main__:train:295 - | epoch  10 |   200/ 1632 batches | lr 0.08 | ms/batch  2.06 | loss  5.68 | ppl   291.95
2025-10-20 19:41:34.961 | INFO     | __main__:train:295 - | epoch  10 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   285.75
2025-10-20 19:41:35.362 | INFO     | __main__:train:295 - | epoch  10 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.18
2025-10-20 19:41:35.762 | INFO     | __main__:train:295 - | epoch  10 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.94
2025-10-20 19:41:36.164 | INFO     | __main__:train:295 - | epoch  10 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.66 | ppl   286.85
2025-10-20 19:41:36.566 | INFO     | __main__:train:295 - | epoch  10 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.72
2025-10-20 19:41:36.968 | INFO     | __main__:train:295 - | epoch  10 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   283.60
2025-10-20 19:41:37.368 | INFO     | __main__:train:295 - | epoch  10 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.53
2025-10-20 19:41:37.613 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:37.613 | INFO     | __main__:<module>:344 - | end of epoch  10 | time:  3.46s | valid loss  5.65 | valid ppl   285.13
2025-10-20 19:41:37.671 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:38.079 | INFO     | __main__:train:295 - | epoch  11 |   200/ 1632 batches | lr 0.08 | ms/batch  2.04 | loss  5.68 | ppl   291.83
2025-10-20 19:41:38.480 | INFO     | __main__:train:295 - | epoch  11 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.64
2025-10-20 19:41:38.882 | INFO     | __main__:train:295 - | epoch  11 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.11
2025-10-20 19:41:39.286 | INFO     | __main__:train:295 - | epoch  11 |   800/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   284.87
2025-10-20 19:41:39.688 | INFO     | __main__:train:295 - | epoch  11 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.66 | ppl   286.75
2025-10-20 19:41:40.088 | INFO     | __main__:train:295 - | epoch  11 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.71
2025-10-20 19:41:40.490 | INFO     | __main__:train:295 - | epoch  11 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   283.56
2025-10-20 19:41:40.892 | INFO     | __main__:train:295 - | epoch  11 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.60
2025-10-20 19:41:41.143 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:41.143 | INFO     | __main__:<module>:344 - | end of epoch  11 | time:  3.47s | valid loss  5.65 | valid ppl   285.10
2025-10-20 19:41:41.194 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:41.602 | INFO     | __main__:train:295 - | epoch  12 |   200/ 1632 batches | lr 0.08 | ms/batch  2.04 | loss  5.68 | ppl   291.61
2025-10-20 19:41:42.004 | INFO     | __main__:train:295 - | epoch  12 |   400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.52
2025-10-20 19:41:42.406 | INFO     | __main__:train:295 - | epoch  12 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.11
2025-10-20 19:41:42.808 | INFO     | __main__:train:295 - | epoch  12 |   800/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.82
2025-10-20 19:41:43.210 | INFO     | __main__:train:295 - | epoch  12 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.66 | ppl   286.73
2025-10-20 19:41:43.611 | INFO     | __main__:train:295 - | epoch  12 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.61
2025-10-20 19:41:44.012 | INFO     | __main__:train:295 - | epoch  12 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   283.54
2025-10-20 19:41:44.418 | INFO     | __main__:train:295 - | epoch  12 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.65 | ppl   284.59
2025-10-20 19:41:44.656 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:44.657 | INFO     | __main__:<module>:344 - | end of epoch  12 | time:  3.46s | valid loss  5.65 | valid ppl   285.09
2025-10-20 19:41:44.735 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:45.146 | INFO     | __main__:train:295 - | epoch  13 |   200/ 1632 batches | lr 0.08 | ms/batch  2.06 | loss  5.68 | ppl   291.61
2025-10-20 19:41:45.547 | INFO     | __main__:train:295 - | epoch  13 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.57
2025-10-20 19:41:45.949 | INFO     | __main__:train:295 - | epoch  13 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.98
2025-10-20 19:41:46.350 | INFO     | __main__:train:295 - | epoch  13 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.79
2025-10-20 19:41:46.750 | INFO     | __main__:train:295 - | epoch  13 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.60
2025-10-20 19:41:47.150 | INFO     | __main__:train:295 - | epoch  13 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.51
2025-10-20 19:41:47.550 | INFO     | __main__:train:295 - | epoch  13 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   283.47
2025-10-20 19:41:47.950 | INFO     | __main__:train:295 - | epoch  13 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.55
2025-10-20 19:41:48.187 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:48.187 | INFO     | __main__:<module>:344 - | end of epoch  13 | time:  3.45s | valid loss  5.65 | valid ppl   285.05
2025-10-20 19:41:48.247 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:48.665 | INFO     | __main__:train:295 - | epoch  14 |   200/ 1632 batches | lr 0.08 | ms/batch  2.09 | loss  5.67 | ppl   291.44
2025-10-20 19:41:49.066 | INFO     | __main__:train:295 - | epoch  14 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.51
2025-10-20 19:41:49.480 | INFO     | __main__:train:295 - | epoch  14 |   600/ 1632 batches | lr 0.08 | ms/batch  2.07 | loss  5.65 | ppl   284.94
2025-10-20 19:41:49.882 | INFO     | __main__:train:295 - | epoch  14 |   800/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.73
2025-10-20 19:41:50.282 | INFO     | __main__:train:295 - | epoch  14 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.62
2025-10-20 19:41:50.684 | INFO     | __main__:train:295 - | epoch  14 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   285.44
2025-10-20 19:41:51.086 | INFO     | __main__:train:295 - | epoch  14 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   283.54
2025-10-20 19:41:51.488 | INFO     | __main__:train:295 - | epoch  14 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.54
2025-10-20 19:41:51.742 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:51.742 | INFO     | __main__:<module>:344 - | end of epoch  14 | time:  3.49s | valid loss  5.65 | valid ppl   285.05
2025-10-20 19:41:51.742 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:41:51.742 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.01953125
2025-10-20 19:41:51.774 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:52.195 | INFO     | __main__:train:295 - | epoch  15 |   200/ 1632 batches | lr 0.02 | ms/batch  2.10 | loss  5.68 | ppl   291.58
2025-10-20 19:41:52.597 | INFO     | __main__:train:295 - | epoch  15 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.50
2025-10-20 19:41:52.999 | INFO     | __main__:train:295 - | epoch  15 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.02
2025-10-20 19:41:53.400 | INFO     | __main__:train:295 - | epoch  15 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.78
2025-10-20 19:41:53.806 | INFO     | __main__:train:295 - | epoch  15 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.66 | ppl   286.57
2025-10-20 19:41:54.212 | INFO     | __main__:train:295 - | epoch  15 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   285.50
2025-10-20 19:41:54.613 | INFO     | __main__:train:295 - | epoch  15 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   283.37
2025-10-20 19:41:55.015 | INFO     | __main__:train:295 - | epoch  15 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.33
2025-10-20 19:41:55.256 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:55.256 | INFO     | __main__:<module>:344 - | end of epoch  15 | time:  3.48s | valid loss  5.65 | valid ppl   285.01
2025-10-20 19:41:55.317 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:55.738 | INFO     | __main__:train:295 - | epoch  16 |   200/ 1632 batches | lr 0.02 | ms/batch  2.11 | loss  5.67 | ppl   291.47
2025-10-20 19:41:56.141 | INFO     | __main__:train:295 - | epoch  16 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.46
2025-10-20 19:41:56.542 | INFO     | __main__:train:295 - | epoch  16 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.88
2025-10-20 19:41:56.944 | INFO     | __main__:train:295 - | epoch  16 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.72
2025-10-20 19:41:57.347 | INFO     | __main__:train:295 - | epoch  16 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   286.50
2025-10-20 19:41:57.761 | INFO     | __main__:train:295 - | epoch  16 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.07 | loss  5.65 | ppl   285.43
2025-10-20 19:41:58.164 | INFO     | __main__:train:295 - | epoch  16 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   283.41
2025-10-20 19:41:58.566 | INFO     | __main__:train:295 - | epoch  16 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.41
2025-10-20 19:41:58.807 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:58.807 | INFO     | __main__:<module>:344 - | end of epoch  16 | time:  3.49s | valid loss  5.65 | valid ppl   285.00
2025-10-20 19:41:58.884 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:41:59.293 | INFO     | __main__:train:295 - | epoch  17 |   200/ 1632 batches | lr 0.02 | ms/batch  2.04 | loss  5.68 | ppl   291.51
2025-10-20 19:41:59.695 | INFO     | __main__:train:295 - | epoch  17 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.43
2025-10-20 19:42:00.097 | INFO     | __main__:train:295 - | epoch  17 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.91
2025-10-20 19:42:00.499 | INFO     | __main__:train:295 - | epoch  17 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.66
2025-10-20 19:42:00.901 | INFO     | __main__:train:295 - | epoch  17 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   286.46
2025-10-20 19:42:01.302 | INFO     | __main__:train:295 - | epoch  17 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.48
2025-10-20 19:42:01.704 | INFO     | __main__:train:295 - | epoch  17 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   283.40
2025-10-20 19:42:02.106 | INFO     | __main__:train:295 - | epoch  17 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.46
2025-10-20 19:42:02.346 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:02.347 | INFO     | __main__:<module>:344 - | end of epoch  17 | time:  3.46s | valid loss  5.65 | valid ppl   285.00
2025-10-20 19:42:02.406 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:02.820 | INFO     | __main__:train:295 - | epoch  18 |   200/ 1632 batches | lr 0.02 | ms/batch  2.07 | loss  5.68 | ppl   291.52
2025-10-20 19:42:03.222 | INFO     | __main__:train:295 - | epoch  18 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.44
2025-10-20 19:42:03.625 | INFO     | __main__:train:295 - | epoch  18 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.79
2025-10-20 19:42:04.028 | INFO     | __main__:train:295 - | epoch  18 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.63
2025-10-20 19:42:04.430 | INFO     | __main__:train:295 - | epoch  18 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   286.50
2025-10-20 19:42:04.832 | INFO     | __main__:train:295 - | epoch  18 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.48
2025-10-20 19:42:05.234 | INFO     | __main__:train:295 - | epoch  18 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   283.47
2025-10-20 19:42:05.638 | INFO     | __main__:train:295 - | epoch  18 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.42
2025-10-20 19:42:05.878 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:05.878 | INFO     | __main__:<module>:344 - | end of epoch  18 | time:  3.47s | valid loss  5.65 | valid ppl   284.99
2025-10-20 19:42:05.940 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:06.348 | INFO     | __main__:train:295 - | epoch  19 |   200/ 1632 batches | lr 0.02 | ms/batch  2.04 | loss  5.67 | ppl   291.44
2025-10-20 19:42:06.752 | INFO     | __main__:train:295 - | epoch  19 |   400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   285.38
2025-10-20 19:42:07.152 | INFO     | __main__:train:295 - | epoch  19 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.84
2025-10-20 19:42:07.554 | INFO     | __main__:train:295 - | epoch  19 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.61
2025-10-20 19:42:07.956 | INFO     | __main__:train:295 - | epoch  19 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   286.49
2025-10-20 19:42:08.359 | INFO     | __main__:train:295 - | epoch  19 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.42
2025-10-20 19:42:08.764 | INFO     | __main__:train:295 - | epoch  19 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   283.43
2025-10-20 19:42:09.183 | INFO     | __main__:train:295 - | epoch  19 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.09 | loss  5.65 | ppl   284.43
2025-10-20 19:42:09.424 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:09.424 | INFO     | __main__:<module>:344 - | end of epoch  19 | time:  3.48s | valid loss  5.65 | valid ppl   284.99
2025-10-20 19:42:09.486 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:09.895 | INFO     | __main__:train:295 - | epoch  20 |   200/ 1632 batches | lr 0.02 | ms/batch  2.04 | loss  5.67 | ppl   291.35
2025-10-20 19:42:10.297 | INFO     | __main__:train:295 - | epoch  20 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.31
2025-10-20 19:42:10.700 | INFO     | __main__:train:295 - | epoch  20 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.80
2025-10-20 19:42:11.102 | INFO     | __main__:train:295 - | epoch  20 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.70
2025-10-20 19:42:11.503 | INFO     | __main__:train:295 - | epoch  20 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   286.48
2025-10-20 19:42:11.906 | INFO     | __main__:train:295 - | epoch  20 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   285.35
2025-10-20 19:42:12.307 | INFO     | __main__:train:295 - | epoch  20 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   283.45
2025-10-20 19:42:12.709 | INFO     | __main__:train:295 - | epoch  20 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.34
2025-10-20 19:42:12.947 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:12.947 | INFO     | __main__:<module>:344 - | end of epoch  20 | time:  3.46s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:42:13.023 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:13.433 | INFO     | __main__:train:295 - | epoch  21 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   291.44
2025-10-20 19:42:13.834 | INFO     | __main__:train:295 - | epoch  21 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   285.42
2025-10-20 19:42:14.236 | INFO     | __main__:train:295 - | epoch  21 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.84
2025-10-20 19:42:14.638 | INFO     | __main__:train:295 - | epoch  21 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.65
2025-10-20 19:42:15.038 | INFO     | __main__:train:295 - | epoch  21 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   286.43
2025-10-20 19:42:15.442 | INFO     | __main__:train:295 - | epoch  21 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   285.37
2025-10-20 19:42:15.844 | INFO     | __main__:train:295 - | epoch  21 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   283.45
2025-10-20 19:42:16.246 | INFO     | __main__:train:295 - | epoch  21 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.42
2025-10-20 19:42:16.485 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:16.485 | INFO     | __main__:<module>:344 - | end of epoch  21 | time:  3.46s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:42:16.485 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:42:16.485 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.0048828125
2025-10-20 19:42:16.517 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:16.924 | INFO     | __main__:train:295 - | epoch  22 |   200/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.67 | ppl   291.37
2025-10-20 19:42:17.325 | INFO     | __main__:train:295 - | epoch  22 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   285.41
2025-10-20 19:42:17.728 | INFO     | __main__:train:295 - | epoch  22 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.83
2025-10-20 19:42:18.128 | INFO     | __main__:train:295 - | epoch  22 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.60
2025-10-20 19:42:18.530 | INFO     | __main__:train:295 - | epoch  22 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   286.43
2025-10-20 19:42:18.932 | INFO     | __main__:train:295 - | epoch  22 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.43
2025-10-20 19:42:19.337 | INFO     | __main__:train:295 - | epoch  22 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.41
2025-10-20 19:42:19.739 | INFO     | __main__:train:295 - | epoch  22 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.44
2025-10-20 19:42:19.980 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:19.980 | INFO     | __main__:<module>:344 - | end of epoch  22 | time:  3.46s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:20.038 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:20.448 | INFO     | __main__:train:295 - | epoch  23 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   291.42
2025-10-20 19:42:20.850 | INFO     | __main__:train:295 - | epoch  23 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.38
2025-10-20 19:42:21.252 | INFO     | __main__:train:295 - | epoch  23 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.79
2025-10-20 19:42:21.654 | INFO     | __main__:train:295 - | epoch  23 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.59
2025-10-20 19:42:22.054 | INFO     | __main__:train:295 - | epoch  23 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   286.47
2025-10-20 19:42:22.455 | INFO     | __main__:train:295 - | epoch  23 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   285.38
2025-10-20 19:42:22.857 | INFO     | __main__:train:295 - | epoch  23 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.34
2025-10-20 19:42:23.258 | INFO     | __main__:train:295 - | epoch  23 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.36
2025-10-20 19:42:23.497 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:23.497 | INFO     | __main__:<module>:344 - | end of epoch  23 | time:  3.46s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:23.576 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:23.986 | INFO     | __main__:train:295 - | epoch  24 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   291.37
2025-10-20 19:42:24.386 | INFO     | __main__:train:295 - | epoch  24 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   285.42
2025-10-20 19:42:24.788 | INFO     | __main__:train:295 - | epoch  24 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.81
2025-10-20 19:42:25.188 | INFO     | __main__:train:295 - | epoch  24 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.63
2025-10-20 19:42:25.590 | INFO     | __main__:train:295 - | epoch  24 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   286.41
2025-10-20 19:42:25.990 | INFO     | __main__:train:295 - | epoch  24 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   285.40
2025-10-20 19:42:26.390 | INFO     | __main__:train:295 - | epoch  24 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   283.43
2025-10-20 19:42:26.791 | INFO     | __main__:train:295 - | epoch  24 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.42
2025-10-20 19:42:27.031 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:27.031 | INFO     | __main__:<module>:344 - | end of epoch  24 | time:  3.46s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:27.091 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:27.498 | INFO     | __main__:train:295 - | epoch  25 |   200/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.67 | ppl   291.48
2025-10-20 19:42:27.901 | INFO     | __main__:train:295 - | epoch  25 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.29
2025-10-20 19:42:28.302 | INFO     | __main__:train:295 - | epoch  25 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.85
2025-10-20 19:42:28.704 | INFO     | __main__:train:295 - | epoch  25 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.61
2025-10-20 19:42:29.105 | INFO     | __main__:train:295 - | epoch  25 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   286.42
2025-10-20 19:42:29.506 | INFO     | __main__:train:295 - | epoch  25 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.34
2025-10-20 19:42:29.911 | INFO     | __main__:train:295 - | epoch  25 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.45
2025-10-20 19:42:30.314 | INFO     | __main__:train:295 - | epoch  25 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.36
2025-10-20 19:42:30.552 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:30.552 | INFO     | __main__:<module>:344 - | end of epoch  25 | time:  3.46s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:30.552 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:42:30.552 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.001220703125
2025-10-20 19:42:30.586 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:31.003 | INFO     | __main__:train:295 - | epoch  26 |   200/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.67 | ppl   291.36
2025-10-20 19:42:31.405 | INFO     | __main__:train:295 - | epoch  26 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.29
2025-10-20 19:42:31.808 | INFO     | __main__:train:295 - | epoch  26 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.82
2025-10-20 19:42:32.210 | INFO     | __main__:train:295 - | epoch  26 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.65
2025-10-20 19:42:32.612 | INFO     | __main__:train:295 - | epoch  26 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   286.42
2025-10-20 19:42:33.016 | INFO     | __main__:train:295 - | epoch  26 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.38
2025-10-20 19:42:33.418 | INFO     | __main__:train:295 - | epoch  26 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.38
2025-10-20 19:42:33.822 | INFO     | __main__:train:295 - | epoch  26 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.38
2025-10-20 19:42:34.062 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:34.062 | INFO     | __main__:<module>:344 - | end of epoch  26 | time:  3.48s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:34.122 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:34.542 | INFO     | __main__:train:295 - | epoch  27 |   200/ 1632 batches | lr 0.00 | ms/batch  2.10 | loss  5.67 | ppl   291.33
2025-10-20 19:42:34.943 | INFO     | __main__:train:295 - | epoch  27 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   285.28
2025-10-20 19:42:35.348 | INFO     | __main__:train:295 - | epoch  27 |   600/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.85
2025-10-20 19:42:35.750 | INFO     | __main__:train:295 - | epoch  27 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.58
2025-10-20 19:42:36.153 | INFO     | __main__:train:295 - | epoch  27 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   286.37
2025-10-20 19:42:36.556 | INFO     | __main__:train:295 - | epoch  27 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.33
2025-10-20 19:42:36.958 | INFO     | __main__:train:295 - | epoch  27 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.32
2025-10-20 19:42:37.360 | INFO     | __main__:train:295 - | epoch  27 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.42
2025-10-20 19:42:37.614 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:37.614 | INFO     | __main__:<module>:344 - | end of epoch  27 | time:  3.49s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:37.614 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:42:37.614 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.00030517578125
2025-10-20 19:42:37.660 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:38.081 | INFO     | __main__:train:295 - | epoch  28 |   200/ 1632 batches | lr 0.00 | ms/batch  2.10 | loss  5.67 | ppl   291.39
2025-10-20 19:42:38.482 | INFO     | __main__:train:295 - | epoch  28 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.31
2025-10-20 19:42:38.884 | INFO     | __main__:train:295 - | epoch  28 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.80
2025-10-20 19:42:39.285 | INFO     | __main__:train:295 - | epoch  28 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.64
2025-10-20 19:42:39.688 | INFO     | __main__:train:295 - | epoch  28 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.66 | ppl   286.45
2025-10-20 19:42:40.092 | INFO     | __main__:train:295 - | epoch  28 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.37
2025-10-20 19:42:40.493 | INFO     | __main__:train:295 - | epoch  28 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.34
2025-10-20 19:42:40.896 | INFO     | __main__:train:295 - | epoch  28 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.34
2025-10-20 19:42:41.146 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:42:41.146 | INFO     | __main__:<module>:344 - | end of epoch  28 | time:  3.49s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:42:41.146 | INFO     | __main__:<module>:367 - | epochs since loss improved: 2
2025-10-20 19:42:41.146 | INFO     | __main__:<module>:368 - | reducing learning rate to 7.62939453125e-05
2025-10-20 19:42:41.178 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:43:48.402 | INFO     | __main__:<module>:82 - Loading data
2025-10-20 19:43:48.402 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-20 19:43:48.409 | INFO     | corpus:__init__:86 - Loaded dictionary from data/CHILDES/train_dict_a7be993a.cached
2025-10-20 19:43:48.409 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/train.txt.original...
2025-10-20 19:43:48.419 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/valid.txt.original...
2025-10-20 19:43:48.420 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/test.txt.original...
2025-10-20 19:43:48.421 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-20 19:43:48.421 | INFO     | __main__:<module>:88 - ( 0.02 )
2025-10-20 19:43:48.421 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-20 19:43:48.421 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-20 19:43:48.424 | INFO     | __main__:<module>:128 - Building the model
2025-10-20 19:43:48.462 | INFO     | __main__:<module>:315 - Running Transformer with args: {'data': 'data/CHILDES', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': False, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-20 19:43:48.462 | INFO     | __main__:<module>:317 - Transformer id: 13f9229b
2025-10-20 19:43:57.656 | INFO     | __main__:train:295 - | epoch   0 |   200/ 1632 batches | lr 20.00 | ms/batch 45.97 | loss  9.33 | ppl 11271.08
2025-10-20 19:43:58.861 | INFO     | __main__:<module>:378 - -----------------------------------------------------------------------------------------
2025-10-20 19:43:58.861 | INFO     | __main__:<module>:379 - Exiting from training early
2025-10-20 19:44:02.848 | INFO     | __main__:<module>:76 - Using GPU ID 0
2025-10-20 19:44:02.948 | INFO     | __main__:<module>:82 - Loading data
2025-10-20 19:44:02.948 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-20 19:44:02.955 | INFO     | corpus:__init__:86 - Loaded dictionary from data/CHILDES/train_dict_a7be993a.cached
2025-10-20 19:44:02.955 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/train.txt.original...
2025-10-20 19:44:02.982 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/valid.txt.original...
2025-10-20 19:44:02.983 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/test.txt.original...
2025-10-20 19:44:02.983 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-20 19:44:02.983 | INFO     | __main__:<module>:88 - ( 0.04 )
2025-10-20 19:44:02.983 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-20 19:44:02.983 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-20 19:44:02.987 | INFO     | __main__:<module>:128 - Building the model
2025-10-20 19:44:03.027 | INFO     | __main__:<module>:315 - Running Transformer with args: {'data': 'data/CHILDES', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': True, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-20 19:44:03.027 | INFO     | __main__:<module>:317 - Transformer id: d25ef8a2
2025-10-20 19:44:03.540 | INFO     | __main__:train:295 - | epoch   0 |   200/ 1632 batches | lr 20.00 | ms/batch  2.56 | loss  9.37 | ppl 11706.53
2025-10-20 19:44:03.939 | INFO     | __main__:train:295 - | epoch   0 |   400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  8.18 | ppl  3576.75
2025-10-20 19:44:04.340 | INFO     | __main__:train:295 - | epoch   0 |   600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  8.22 | ppl  3724.67
2025-10-20 19:44:04.739 | INFO     | __main__:train:295 - | epoch   0 |   800/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.84 | ppl  2531.59
2025-10-20 19:44:05.139 | INFO     | __main__:train:295 - | epoch   0 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.90 | ppl  2705.50
2025-10-20 19:44:05.539 | INFO     | __main__:train:295 - | epoch   0 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.78 | ppl  2385.47
2025-10-20 19:44:05.940 | INFO     | __main__:train:295 - | epoch   0 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.85 | ppl  2564.35
2025-10-20 19:44:06.337 | INFO     | __main__:train:295 - | epoch   0 |  1600/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.84 | ppl  2545.34
2025-10-20 19:44:06.575 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:06.575 | INFO     | __main__:<module>:344 - | end of epoch   0 | time:  3.55s | valid loss  6.62 | valid ppl   746.56
2025-10-20 19:44:06.652 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:07.073 | INFO     | __main__:train:295 - | epoch   1 |   200/ 1632 batches | lr 20.00 | ms/batch  2.10 | loss  7.86 | ppl  2588.13
2025-10-20 19:44:07.474 | INFO     | __main__:train:295 - | epoch   1 |   400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.75 | ppl  2314.76
2025-10-20 19:44:07.872 | INFO     | __main__:train:295 - | epoch   1 |   600/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.73 | ppl  2284.99
2025-10-20 19:44:08.272 | INFO     | __main__:train:295 - | epoch   1 |   800/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.72 | ppl  2246.33
2025-10-20 19:44:08.672 | INFO     | __main__:train:295 - | epoch   1 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.81 | ppl  2458.61
2025-10-20 19:44:09.088 | INFO     | __main__:train:295 - | epoch   1 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.08 | loss  7.95 | ppl  2823.28
2025-10-20 19:44:09.487 | INFO     | __main__:train:295 - | epoch   1 |  1400/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.70 | ppl  2207.06
2025-10-20 19:44:09.890 | INFO     | __main__:train:295 - | epoch   1 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  7.68 | ppl  2158.65
2025-10-20 19:44:10.128 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:10.128 | INFO     | __main__:<module>:344 - | end of epoch   1 | time:  3.48s | valid loss  6.08 | valid ppl   436.14
2025-10-20 19:44:10.195 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:10.603 | INFO     | __main__:train:295 - | epoch   2 |   200/ 1632 batches | lr 20.00 | ms/batch  2.04 | loss  7.66 | ppl  2111.93
2025-10-20 19:44:11.002 | INFO     | __main__:train:295 - | epoch   2 |   400/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.37 | ppl  1586.88
2025-10-20 19:44:11.401 | INFO     | __main__:train:295 - | epoch   2 |   600/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.50 | ppl  1805.69
2025-10-20 19:44:11.800 | INFO     | __main__:train:295 - | epoch   2 |   800/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  7.41 | ppl  1651.13
2025-10-20 19:44:12.198 | INFO     | __main__:train:295 - | epoch   2 |  1000/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  6.83 | ppl   925.41
2025-10-20 19:44:12.600 | INFO     | __main__:train:295 - | epoch   2 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  6.94 | ppl  1030.91
2025-10-20 19:44:13.001 | INFO     | __main__:train:295 - | epoch   2 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  6.99 | ppl  1085.97
2025-10-20 19:44:13.400 | INFO     | __main__:train:295 - | epoch   2 |  1600/ 1632 batches | lr 20.00 | ms/batch  1.99 | loss  6.93 | ppl  1026.91
2025-10-20 19:44:13.640 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:13.641 | INFO     | __main__:<module>:344 - | end of epoch   2 | time:  3.45s | valid loss 12.47 | valid ppl 260969.88
2025-10-20 19:44:13.641 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:44:13.641 | INFO     | __main__:<module>:368 - | reducing learning rate to 5.0
2025-10-20 19:44:13.672 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:14.079 | INFO     | __main__:train:295 - | epoch   3 |   200/ 1632 batches | lr 5.00 | ms/batch  2.03 | loss  5.74 | ppl   311.05
2025-10-20 19:44:14.480 | INFO     | __main__:train:295 - | epoch   3 |   400/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.71 | ppl   300.39
2025-10-20 19:44:14.913 | INFO     | __main__:train:295 - | epoch   3 |   600/ 1632 batches | lr 5.00 | ms/batch  2.16 | loss  5.70 | ppl   299.42
2025-10-20 19:44:15.314 | INFO     | __main__:train:295 - | epoch   3 |   800/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.70 | ppl   298.76
2025-10-20 19:44:15.714 | INFO     | __main__:train:295 - | epoch   3 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.70 | ppl   299.95
2025-10-20 19:44:16.114 | INFO     | __main__:train:295 - | epoch   3 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.70 | ppl   298.39
2025-10-20 19:44:16.514 | INFO     | __main__:train:295 - | epoch   3 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   295.66
2025-10-20 19:44:16.914 | INFO     | __main__:train:295 - | epoch   3 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   297.21
2025-10-20 19:44:17.155 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:17.155 | INFO     | __main__:<module>:344 - | end of epoch   3 | time:  3.48s | valid loss  5.75 | valid ppl   315.42
2025-10-20 19:44:17.221 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:17.630 | INFO     | __main__:train:295 - | epoch   4 |   200/ 1632 batches | lr 5.00 | ms/batch  2.04 | loss  5.71 | ppl   303.08
2025-10-20 19:44:18.030 | INFO     | __main__:train:295 - | epoch   4 |   400/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   295.72
2025-10-20 19:44:18.430 | INFO     | __main__:train:295 - | epoch   4 |   600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   295.48
2025-10-20 19:44:18.830 | INFO     | __main__:train:295 - | epoch   4 |   800/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   294.82
2025-10-20 19:44:19.230 | INFO     | __main__:train:295 - | epoch   4 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   297.11
2025-10-20 19:44:19.630 | INFO     | __main__:train:295 - | epoch   4 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   295.50
2025-10-20 19:44:20.030 | INFO     | __main__:train:295 - | epoch   4 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   292.67
2025-10-20 19:44:20.430 | INFO     | __main__:train:295 - | epoch   4 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   294.40
2025-10-20 19:44:20.672 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:20.672 | INFO     | __main__:<module>:344 - | end of epoch   4 | time:  3.45s | valid loss  5.75 | valid ppl   315.27
2025-10-20 19:44:20.747 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:21.154 | INFO     | __main__:train:295 - | epoch   5 |   200/ 1632 batches | lr 5.00 | ms/batch  2.04 | loss  5.71 | ppl   300.41
2025-10-20 19:44:21.556 | INFO     | __main__:train:295 - | epoch   5 |   400/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.68 | ppl   293.54
2025-10-20 19:44:21.958 | INFO     | __main__:train:295 - | epoch   5 |   600/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.68 | ppl   292.75
2025-10-20 19:44:22.358 | INFO     | __main__:train:295 - | epoch   5 |   800/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   292.56
2025-10-20 19:44:22.758 | INFO     | __main__:train:295 - | epoch   5 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.69 | ppl   295.16
2025-10-20 19:44:23.158 | INFO     | __main__:train:295 - | epoch   5 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   293.47
2025-10-20 19:44:23.558 | INFO     | __main__:train:295 - | epoch   5 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.67 | ppl   290.40
2025-10-20 19:44:23.958 | INFO     | __main__:train:295 - | epoch   5 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   292.90
2025-10-20 19:44:24.204 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:24.204 | INFO     | __main__:<module>:344 - | end of epoch   5 | time:  3.46s | valid loss  5.73 | valid ppl   309.18
2025-10-20 19:44:24.264 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:24.683 | INFO     | __main__:train:295 - | epoch   6 |   200/ 1632 batches | lr 5.00 | ms/batch  2.10 | loss  5.70 | ppl   298.90
2025-10-20 19:44:25.086 | INFO     | __main__:train:295 - | epoch   6 |   400/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.68 | ppl   291.92
2025-10-20 19:44:25.486 | INFO     | __main__:train:295 - | epoch   6 |   600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.67 | ppl   291.42
2025-10-20 19:44:25.886 | INFO     | __main__:train:295 - | epoch   6 |   800/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   291.51
2025-10-20 19:44:26.286 | INFO     | __main__:train:295 - | epoch   6 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   293.63
2025-10-20 19:44:26.686 | INFO     | __main__:train:295 - | epoch   6 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   291.91
2025-10-20 19:44:27.086 | INFO     | __main__:train:295 - | epoch   6 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.67 | ppl   289.23
2025-10-20 19:44:27.486 | INFO     | __main__:train:295 - | epoch   6 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.00 | loss  5.68 | ppl   291.69
2025-10-20 19:44:27.729 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:27.729 | INFO     | __main__:<module>:344 - | end of epoch   6 | time:  3.46s | valid loss  5.74 | valid ppl   310.81
2025-10-20 19:44:27.729 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:44:27.729 | INFO     | __main__:<module>:368 - | reducing learning rate to 1.25
2025-10-20 19:44:27.761 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:28.170 | INFO     | __main__:train:295 - | epoch   7 |   200/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.68 | ppl   293.51
2025-10-20 19:44:28.570 | INFO     | __main__:train:295 - | epoch   7 |   400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.89
2025-10-20 19:44:28.970 | INFO     | __main__:train:295 - | epoch   7 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.29
2025-10-20 19:44:29.370 | INFO     | __main__:train:295 - | epoch   7 |   800/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.06
2025-10-20 19:44:29.772 | INFO     | __main__:train:295 - | epoch   7 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.85
2025-10-20 19:44:30.172 | INFO     | __main__:train:295 - | epoch   7 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.79
2025-10-20 19:44:30.572 | INFO     | __main__:train:295 - | epoch   7 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   284.63
2025-10-20 19:44:30.972 | INFO     | __main__:train:295 - | epoch   7 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   285.87
2025-10-20 19:44:31.210 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:31.211 | INFO     | __main__:<module>:344 - | end of epoch   7 | time:  3.45s | valid loss  5.66 | valid ppl   287.56
2025-10-20 19:44:31.269 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:31.684 | INFO     | __main__:train:295 - | epoch   8 |   200/ 1632 batches | lr 1.25 | ms/batch  2.07 | loss  5.68 | ppl   292.49
2025-10-20 19:44:32.084 | INFO     | __main__:train:295 - | epoch   8 |   400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.45
2025-10-20 19:44:32.484 | INFO     | __main__:train:295 - | epoch   8 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   285.93
2025-10-20 19:44:32.884 | INFO     | __main__:train:295 - | epoch   8 |   800/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.68
2025-10-20 19:44:33.286 | INFO     | __main__:train:295 - | epoch   8 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.57
2025-10-20 19:44:33.688 | INFO     | __main__:train:295 - | epoch   8 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.56
2025-10-20 19:44:34.090 | INFO     | __main__:train:295 - | epoch   8 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   284.42
2025-10-20 19:44:34.490 | INFO     | __main__:train:295 - | epoch   8 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.72
2025-10-20 19:44:34.730 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:34.730 | INFO     | __main__:<module>:344 - | end of epoch   8 | time:  3.46s | valid loss  5.66 | valid ppl   287.45
2025-10-20 19:44:34.813 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:35.220 | INFO     | __main__:train:295 - | epoch   9 |   200/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.68 | ppl   292.21
2025-10-20 19:44:35.620 | INFO     | __main__:train:295 - | epoch   9 |   400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.25
2025-10-20 19:44:36.020 | INFO     | __main__:train:295 - | epoch   9 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.69
2025-10-20 19:44:36.420 | INFO     | __main__:train:295 - | epoch   9 |   800/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.46
2025-10-20 19:44:36.820 | INFO     | __main__:train:295 - | epoch   9 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   287.37
2025-10-20 19:44:37.220 | INFO     | __main__:train:295 - | epoch   9 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.38
2025-10-20 19:44:37.620 | INFO     | __main__:train:295 - | epoch   9 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   284.25
2025-10-20 19:44:38.022 | INFO     | __main__:train:295 - | epoch   9 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.55
2025-10-20 19:44:38.264 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:38.264 | INFO     | __main__:<module>:344 - | end of epoch   9 | time:  3.45s | valid loss  5.66 | valid ppl   287.40
2025-10-20 19:44:38.322 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:38.728 | INFO     | __main__:train:295 - | epoch  10 |   200/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.68 | ppl   292.03
2025-10-20 19:44:39.128 | INFO     | __main__:train:295 - | epoch  10 |   400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   286.05
2025-10-20 19:44:39.528 | INFO     | __main__:train:295 - | epoch  10 |   600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.52
2025-10-20 19:44:39.928 | INFO     | __main__:train:295 - | epoch  10 |   800/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.29
2025-10-20 19:44:40.328 | INFO     | __main__:train:295 - | epoch  10 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.66 | ppl   287.18
2025-10-20 19:44:40.734 | INFO     | __main__:train:295 - | epoch  10 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.66 | ppl   286.22
2025-10-20 19:44:41.134 | INFO     | __main__:train:295 - | epoch  10 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   284.11
2025-10-20 19:44:41.534 | INFO     | __main__:train:295 - | epoch  10 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.00 | loss  5.65 | ppl   285.43
2025-10-20 19:44:41.774 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:41.774 | INFO     | __main__:<module>:344 - | end of epoch  10 | time:  3.45s | valid loss  5.66 | valid ppl   287.42
2025-10-20 19:44:41.774 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:44:41.774 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.3125
2025-10-20 19:44:41.805 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:42.212 | INFO     | __main__:train:295 - | epoch  11 |   200/ 1632 batches | lr 0.31 | ms/batch  2.03 | loss  5.68 | ppl   291.90
2025-10-20 19:44:42.616 | INFO     | __main__:train:295 - | epoch  11 |   400/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.66 | ppl   285.73
2025-10-20 19:44:43.016 | INFO     | __main__:train:295 - | epoch  11 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.07
2025-10-20 19:44:43.416 | INFO     | __main__:train:295 - | epoch  11 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.91
2025-10-20 19:44:43.818 | INFO     | __main__:train:295 - | epoch  11 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.66 | ppl   286.71
2025-10-20 19:44:44.221 | INFO     | __main__:train:295 - | epoch  11 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.65 | ppl   285.71
2025-10-20 19:44:44.622 | INFO     | __main__:train:295 - | epoch  11 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.61
2025-10-20 19:44:45.023 | INFO     | __main__:train:295 - | epoch  11 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.75
2025-10-20 19:44:45.266 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:45.266 | INFO     | __main__:<module>:344 - | end of epoch  11 | time:  3.46s | valid loss  5.65 | valid ppl   285.66
2025-10-20 19:44:45.324 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:45.732 | INFO     | __main__:train:295 - | epoch  12 |   200/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.68 | ppl   291.52
2025-10-20 19:44:46.132 | INFO     | __main__:train:295 - | epoch  12 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.53
2025-10-20 19:44:46.532 | INFO     | __main__:train:295 - | epoch  12 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:44:46.933 | INFO     | __main__:train:295 - | epoch  12 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.81
2025-10-20 19:44:47.334 | INFO     | __main__:train:295 - | epoch  12 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.64
2025-10-20 19:44:47.734 | INFO     | __main__:train:295 - | epoch  12 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.65
2025-10-20 19:44:48.134 | INFO     | __main__:train:295 - | epoch  12 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.56
2025-10-20 19:44:48.534 | INFO     | __main__:train:295 - | epoch  12 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.74
2025-10-20 19:44:48.772 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:48.772 | INFO     | __main__:<module>:344 - | end of epoch  12 | time:  3.45s | valid loss  5.65 | valid ppl   285.59
2025-10-20 19:44:48.845 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:49.256 | INFO     | __main__:train:295 - | epoch  13 |   200/ 1632 batches | lr 0.31 | ms/batch  2.05 | loss  5.67 | ppl   291.44
2025-10-20 19:44:49.656 | INFO     | __main__:train:295 - | epoch  13 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.47
2025-10-20 19:44:50.056 | INFO     | __main__:train:295 - | epoch  13 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.89
2025-10-20 19:44:50.456 | INFO     | __main__:train:295 - | epoch  13 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.74
2025-10-20 19:44:50.858 | INFO     | __main__:train:295 - | epoch  13 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.66 | ppl   286.58
2025-10-20 19:44:51.258 | INFO     | __main__:train:295 - | epoch  13 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.63
2025-10-20 19:44:51.658 | INFO     | __main__:train:295 - | epoch  13 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.53
2025-10-20 19:44:52.058 | INFO     | __main__:train:295 - | epoch  13 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.73
2025-10-20 19:44:52.296 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:52.296 | INFO     | __main__:<module>:344 - | end of epoch  13 | time:  3.45s | valid loss  5.65 | valid ppl   285.52
2025-10-20 19:44:52.364 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:52.776 | INFO     | __main__:train:295 - | epoch  14 |   200/ 1632 batches | lr 0.31 | ms/batch  2.06 | loss  5.67 | ppl   291.38
2025-10-20 19:44:53.176 | INFO     | __main__:train:295 - | epoch  14 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.40
2025-10-20 19:44:53.575 | INFO     | __main__:train:295 - | epoch  14 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.83
2025-10-20 19:44:53.976 | INFO     | __main__:train:295 - | epoch  14 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.70
2025-10-20 19:44:54.376 | INFO     | __main__:train:295 - | epoch  14 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.54
2025-10-20 19:44:54.794 | INFO     | __main__:train:295 - | epoch  14 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.09 | loss  5.65 | ppl   285.58
2025-10-20 19:44:55.194 | INFO     | __main__:train:295 - | epoch  14 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.50
2025-10-20 19:44:55.594 | INFO     | __main__:train:295 - | epoch  14 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.70
2025-10-20 19:44:55.834 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:55.834 | INFO     | __main__:<module>:344 - | end of epoch  14 | time:  3.47s | valid loss  5.65 | valid ppl   285.50
2025-10-20 19:44:55.892 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:56.298 | INFO     | __main__:train:295 - | epoch  15 |   200/ 1632 batches | lr 0.31 | ms/batch  2.03 | loss  5.67 | ppl   291.32
2025-10-20 19:44:56.698 | INFO     | __main__:train:295 - | epoch  15 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.36
2025-10-20 19:44:57.098 | INFO     | __main__:train:295 - | epoch  15 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.79
2025-10-20 19:44:57.498 | INFO     | __main__:train:295 - | epoch  15 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.66
2025-10-20 19:44:57.898 | INFO     | __main__:train:295 - | epoch  15 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.51
2025-10-20 19:44:58.298 | INFO     | __main__:train:295 - | epoch  15 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.53
2025-10-20 19:44:58.698 | INFO     | __main__:train:295 - | epoch  15 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.46
2025-10-20 19:44:59.098 | INFO     | __main__:train:295 - | epoch  15 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.69
2025-10-20 19:44:59.336 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:59.336 | INFO     | __main__:<module>:344 - | end of epoch  15 | time:  3.44s | valid loss  5.65 | valid ppl   285.48
2025-10-20 19:44:59.394 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:44:59.802 | INFO     | __main__:train:295 - | epoch  16 |   200/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.67 | ppl   291.27
2025-10-20 19:45:00.202 | INFO     | __main__:train:295 - | epoch  16 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.32
2025-10-20 19:45:00.602 | INFO     | __main__:train:295 - | epoch  16 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.74
2025-10-20 19:45:01.002 | INFO     | __main__:train:295 - | epoch  16 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.60
2025-10-20 19:45:01.402 | INFO     | __main__:train:295 - | epoch  16 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.46
2025-10-20 19:45:01.802 | INFO     | __main__:train:295 - | epoch  16 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.51
2025-10-20 19:45:02.202 | INFO     | __main__:train:295 - | epoch  16 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.43
2025-10-20 19:45:02.601 | INFO     | __main__:train:295 - | epoch  16 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.66
2025-10-20 19:45:02.840 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:02.840 | INFO     | __main__:<module>:344 - | end of epoch  16 | time:  3.45s | valid loss  5.65 | valid ppl   285.46
2025-10-20 19:45:02.899 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:03.312 | INFO     | __main__:train:295 - | epoch  17 |   200/ 1632 batches | lr 0.31 | ms/batch  2.06 | loss  5.67 | ppl   291.22
2025-10-20 19:45:03.712 | INFO     | __main__:train:295 - | epoch  17 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.28
2025-10-20 19:45:04.112 | INFO     | __main__:train:295 - | epoch  17 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.70
2025-10-20 19:45:04.512 | INFO     | __main__:train:295 - | epoch  17 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.58
2025-10-20 19:45:04.912 | INFO     | __main__:train:295 - | epoch  17 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.40
2025-10-20 19:45:05.312 | INFO     | __main__:train:295 - | epoch  17 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.48
2025-10-20 19:45:05.712 | INFO     | __main__:train:295 - | epoch  17 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.40
2025-10-20 19:45:06.112 | INFO     | __main__:train:295 - | epoch  17 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.63
2025-10-20 19:45:06.361 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:06.361 | INFO     | __main__:<module>:344 - | end of epoch  17 | time:  3.46s | valid loss  5.65 | valid ppl   285.44
2025-10-20 19:45:06.435 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:06.844 | INFO     | __main__:train:295 - | epoch  18 |   200/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.67 | ppl   291.18
2025-10-20 19:45:07.258 | INFO     | __main__:train:295 - | epoch  18 |   400/ 1632 batches | lr 0.31 | ms/batch  2.07 | loss  5.65 | ppl   285.24
2025-10-20 19:45:07.658 | INFO     | __main__:train:295 - | epoch  18 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.66
2025-10-20 19:45:08.057 | INFO     | __main__:train:295 - | epoch  18 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.54
2025-10-20 19:45:08.458 | INFO     | __main__:train:295 - | epoch  18 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.39
2025-10-20 19:45:08.869 | INFO     | __main__:train:295 - | epoch  18 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.06 | loss  5.65 | ppl   285.43
2025-10-20 19:45:09.270 | INFO     | __main__:train:295 - | epoch  18 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.37
2025-10-20 19:45:09.670 | INFO     | __main__:train:295 - | epoch  18 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.60
2025-10-20 19:45:09.910 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:09.910 | INFO     | __main__:<module>:344 - | end of epoch  18 | time:  3.47s | valid loss  5.65 | valid ppl   285.41
2025-10-20 19:45:09.970 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:10.378 | INFO     | __main__:train:295 - | epoch  19 |   200/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.67 | ppl   291.14
2025-10-20 19:45:10.778 | INFO     | __main__:train:295 - | epoch  19 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.20
2025-10-20 19:45:11.178 | INFO     | __main__:train:295 - | epoch  19 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.62
2025-10-20 19:45:11.578 | INFO     | __main__:train:295 - | epoch  19 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.48
2025-10-20 19:45:11.978 | INFO     | __main__:train:295 - | epoch  19 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.35
2025-10-20 19:45:12.378 | INFO     | __main__:train:295 - | epoch  19 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.40
2025-10-20 19:45:12.778 | INFO     | __main__:train:295 - | epoch  19 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.34
2025-10-20 19:45:13.178 | INFO     | __main__:train:295 - | epoch  19 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.57
2025-10-20 19:45:13.417 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:13.417 | INFO     | __main__:<module>:344 - | end of epoch  19 | time:  3.45s | valid loss  5.65 | valid ppl   285.40
2025-10-20 19:45:13.477 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:13.883 | INFO     | __main__:train:295 - | epoch  20 |   200/ 1632 batches | lr 0.31 | ms/batch  2.03 | loss  5.67 | ppl   291.09
2025-10-20 19:45:14.284 | INFO     | __main__:train:295 - | epoch  20 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.16
2025-10-20 19:45:14.684 | INFO     | __main__:train:295 - | epoch  20 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.60
2025-10-20 19:45:15.084 | INFO     | __main__:train:295 - | epoch  20 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.45
2025-10-20 19:45:15.484 | INFO     | __main__:train:295 - | epoch  20 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.32
2025-10-20 19:45:15.886 | INFO     | __main__:train:295 - | epoch  20 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   285.37
2025-10-20 19:45:16.286 | INFO     | __main__:train:295 - | epoch  20 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.31
2025-10-20 19:45:16.686 | INFO     | __main__:train:295 - | epoch  20 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.53
2025-10-20 19:45:16.923 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:16.923 | INFO     | __main__:<module>:344 - | end of epoch  20 | time:  3.45s | valid loss  5.65 | valid ppl   285.39
2025-10-20 19:45:17.007 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:17.434 | INFO     | __main__:train:295 - | epoch  21 |   200/ 1632 batches | lr 0.31 | ms/batch  2.13 | loss  5.67 | ppl   291.05
2025-10-20 19:45:17.843 | INFO     | __main__:train:295 - | epoch  21 |   400/ 1632 batches | lr 0.31 | ms/batch  2.04 | loss  5.65 | ppl   285.14
2025-10-20 19:45:18.243 | INFO     | __main__:train:295 - | epoch  21 |   600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.56
2025-10-20 19:45:18.642 | INFO     | __main__:train:295 - | epoch  21 |   800/ 1632 batches | lr 0.31 | ms/batch  1.99 | loss  5.65 | ppl   284.42
2025-10-20 19:45:19.042 | INFO     | __main__:train:295 - | epoch  21 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.66 | ppl   286.28
2025-10-20 19:45:19.442 | INFO     | __main__:train:295 - | epoch  21 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.34
2025-10-20 19:45:19.842 | INFO     | __main__:train:295 - | epoch  21 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   283.27
2025-10-20 19:45:20.242 | INFO     | __main__:train:295 - | epoch  21 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.51
2025-10-20 19:45:20.478 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:20.478 | INFO     | __main__:<module>:344 - | end of epoch  21 | time:  3.47s | valid loss  5.65 | valid ppl   285.36
2025-10-20 19:45:20.546 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:20.948 | INFO     | __main__:train:295 - | epoch  22 |   200/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.67 | ppl   291.03
2025-10-20 19:45:21.348 | INFO     | __main__:train:295 - | epoch  22 |   400/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.12
2025-10-20 19:45:21.750 | INFO     | __main__:train:295 - | epoch  22 |   600/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   284.53
2025-10-20 19:45:22.149 | INFO     | __main__:train:295 - | epoch  22 |   800/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.39
2025-10-20 19:45:22.548 | INFO     | __main__:train:295 - | epoch  22 |  1000/ 1632 batches | lr 0.31 | ms/batch  1.99 | loss  5.66 | ppl   286.25
2025-10-20 19:45:22.948 | INFO     | __main__:train:295 - | epoch  22 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   285.31
2025-10-20 19:45:23.349 | INFO     | __main__:train:295 - | epoch  22 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   283.26
2025-10-20 19:45:23.750 | INFO     | __main__:train:295 - | epoch  22 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.00 | loss  5.65 | ppl   284.49
2025-10-20 19:45:23.990 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:23.991 | INFO     | __main__:<module>:344 - | end of epoch  22 | time:  3.44s | valid loss  5.65 | valid ppl   285.36
2025-10-20 19:45:23.991 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:45:23.991 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.078125
2025-10-20 19:45:24.022 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:24.440 | INFO     | __main__:train:295 - | epoch  23 |   200/ 1632 batches | lr 0.08 | ms/batch  2.09 | loss  5.67 | ppl   291.04
2025-10-20 19:45:24.840 | INFO     | __main__:train:295 - | epoch  23 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.06
2025-10-20 19:45:25.240 | INFO     | __main__:train:295 - | epoch  23 |   600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.41
2025-10-20 19:45:25.640 | INFO     | __main__:train:295 - | epoch  23 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.25
2025-10-20 19:45:26.040 | INFO     | __main__:train:295 - | epoch  23 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.08
2025-10-20 19:45:26.440 | INFO     | __main__:train:295 - | epoch  23 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.10
2025-10-20 19:45:26.839 | INFO     | __main__:train:295 - | epoch  23 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   283.07
2025-10-20 19:45:27.240 | INFO     | __main__:train:295 - | epoch  23 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:45:27.475 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:27.475 | INFO     | __main__:<module>:344 - | end of epoch  23 | time:  3.45s | valid loss  5.65 | valid ppl   285.09
2025-10-20 19:45:27.533 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:27.942 | INFO     | __main__:train:295 - | epoch  24 |   200/ 1632 batches | lr 0.08 | ms/batch  2.04 | loss  5.67 | ppl   290.88
2025-10-20 19:45:28.341 | INFO     | __main__:train:295 - | epoch  24 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:45:28.742 | INFO     | __main__:train:295 - | epoch  24 |   600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.36
2025-10-20 19:45:29.142 | INFO     | __main__:train:295 - | epoch  24 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.20
2025-10-20 19:45:29.542 | INFO     | __main__:train:295 - | epoch  24 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.06
2025-10-20 19:45:29.943 | INFO     | __main__:train:295 - | epoch  24 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.09
2025-10-20 19:45:30.346 | INFO     | __main__:train:295 - | epoch  24 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   283.08
2025-10-20 19:45:30.747 | INFO     | __main__:train:295 - | epoch  24 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.22
2025-10-20 19:45:30.985 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:30.985 | INFO     | __main__:<module>:344 - | end of epoch  24 | time:  3.45s | valid loss  5.65 | valid ppl   285.08
2025-10-20 19:45:31.069 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:31.488 | INFO     | __main__:train:295 - | epoch  25 |   200/ 1632 batches | lr 0.08 | ms/batch  2.09 | loss  5.67 | ppl   290.85
2025-10-20 19:45:31.890 | INFO     | __main__:train:295 - | epoch  25 |   400/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.96
2025-10-20 19:45:32.290 | INFO     | __main__:train:295 - | epoch  25 |   600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.33
2025-10-20 19:45:32.690 | INFO     | __main__:train:295 - | epoch  25 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.20
2025-10-20 19:45:33.090 | INFO     | __main__:train:295 - | epoch  25 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.05
2025-10-20 19:45:33.490 | INFO     | __main__:train:295 - | epoch  25 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.08
2025-10-20 19:45:33.890 | INFO     | __main__:train:295 - | epoch  25 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   283.07
2025-10-20 19:45:34.290 | INFO     | __main__:train:295 - | epoch  25 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.23
2025-10-20 19:45:34.532 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:34.532 | INFO     | __main__:<module>:344 - | end of epoch  25 | time:  3.46s | valid loss  5.65 | valid ppl   285.06
2025-10-20 19:45:34.591 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:34.997 | INFO     | __main__:train:295 - | epoch  26 |   200/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.67 | ppl   290.82
2025-10-20 19:45:35.398 | INFO     | __main__:train:295 - | epoch  26 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.93
2025-10-20 19:45:35.800 | INFO     | __main__:train:295 - | epoch  26 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.32
2025-10-20 19:45:36.200 | INFO     | __main__:train:295 - | epoch  26 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.18
2025-10-20 19:45:36.600 | INFO     | __main__:train:295 - | epoch  26 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.04
2025-10-20 19:45:37.000 | INFO     | __main__:train:295 - | epoch  26 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.08
2025-10-20 19:45:37.399 | INFO     | __main__:train:295 - | epoch  26 |  1400/ 1632 batches | lr 0.08 | ms/batch  1.99 | loss  5.65 | ppl   283.06
2025-10-20 19:45:37.798 | INFO     | __main__:train:295 - | epoch  26 |  1600/ 1632 batches | lr 0.08 | ms/batch  1.99 | loss  5.65 | ppl   284.23
2025-10-20 19:45:38.038 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:38.038 | INFO     | __main__:<module>:344 - | end of epoch  26 | time:  3.45s | valid loss  5.65 | valid ppl   285.05
2025-10-20 19:45:38.105 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:38.535 | INFO     | __main__:train:295 - | epoch  27 |   200/ 1632 batches | lr 0.08 | ms/batch  2.15 | loss  5.67 | ppl   290.81
2025-10-20 19:45:38.935 | INFO     | __main__:train:295 - | epoch  27 |   400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.92
2025-10-20 19:45:39.337 | INFO     | __main__:train:295 - | epoch  27 |   600/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.65 | ppl   284.31
2025-10-20 19:45:39.738 | INFO     | __main__:train:295 - | epoch  27 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.17
2025-10-20 19:45:40.138 | INFO     | __main__:train:295 - | epoch  27 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.66 | ppl   286.03
2025-10-20 19:45:40.538 | INFO     | __main__:train:295 - | epoch  27 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.08
2025-10-20 19:45:40.938 | INFO     | __main__:train:295 - | epoch  27 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   283.06
2025-10-20 19:45:41.338 | INFO     | __main__:train:295 - | epoch  27 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.23
2025-10-20 19:45:41.580 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:41.580 | INFO     | __main__:<module>:344 - | end of epoch  27 | time:  3.47s | valid loss  5.65 | valid ppl   285.04
2025-10-20 19:45:41.639 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:42.046 | INFO     | __main__:train:295 - | epoch  28 |   200/ 1632 batches | lr 0.08 | ms/batch  2.04 | loss  5.67 | ppl   290.79
2025-10-20 19:45:42.452 | INFO     | __main__:train:295 - | epoch  28 |   400/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.65 | ppl   284.91
2025-10-20 19:45:42.852 | INFO     | __main__:train:295 - | epoch  28 |   600/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.30
2025-10-20 19:45:43.252 | INFO     | __main__:train:295 - | epoch  28 |   800/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   284.16
2025-10-20 19:45:43.655 | INFO     | __main__:train:295 - | epoch  28 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.01 | loss  5.66 | ppl   286.01
2025-10-20 19:45:44.055 | INFO     | __main__:train:295 - | epoch  28 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   285.06
2025-10-20 19:45:44.456 | INFO     | __main__:train:295 - | epoch  28 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.00 | loss  5.65 | ppl   283.05
2025-10-20 19:45:44.860 | INFO     | __main__:train:295 - | epoch  28 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   284.22
2025-10-20 19:45:45.100 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:45.100 | INFO     | __main__:<module>:344 - | end of epoch  28 | time:  3.46s | valid loss  5.65 | valid ppl   285.04
2025-10-20 19:45:45.100 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:45:45.100 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.01953125
2025-10-20 19:45:45.148 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:45.573 | INFO     | __main__:train:295 - | epoch  29 |   200/ 1632 batches | lr 0.02 | ms/batch  2.13 | loss  5.67 | ppl   290.80
2025-10-20 19:45:45.974 | INFO     | __main__:train:295 - | epoch  29 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.90
2025-10-20 19:45:46.374 | INFO     | __main__:train:295 - | epoch  29 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.29
2025-10-20 19:45:46.775 | INFO     | __main__:train:295 - | epoch  29 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:45:47.176 | INFO     | __main__:train:295 - | epoch  29 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   285.95
2025-10-20 19:45:47.576 | INFO     | __main__:train:295 - | epoch  29 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.99
2025-10-20 19:45:47.976 | INFO     | __main__:train:295 - | epoch  29 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.97
2025-10-20 19:45:48.376 | INFO     | __main__:train:295 - | epoch  29 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.13
2025-10-20 19:45:48.614 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:48.614 | INFO     | __main__:<module>:344 - | end of epoch  29 | time:  3.47s | valid loss  5.65 | valid ppl   284.99
2025-10-20 19:45:48.668 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:49.074 | INFO     | __main__:train:295 - | epoch  30 |   200/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.67 | ppl   290.76
2025-10-20 19:45:49.474 | INFO     | __main__:train:295 - | epoch  30 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.87
2025-10-20 19:45:49.876 | INFO     | __main__:train:295 - | epoch  30 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.26
2025-10-20 19:45:50.277 | INFO     | __main__:train:295 - | epoch  30 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.11
2025-10-20 19:45:50.679 | INFO     | __main__:train:295 - | epoch  30 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   285.95
2025-10-20 19:45:51.080 | INFO     | __main__:train:295 - | epoch  30 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:45:51.480 | INFO     | __main__:train:295 - | epoch  30 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.98
2025-10-20 19:45:51.880 | INFO     | __main__:train:295 - | epoch  30 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.13
2025-10-20 19:45:52.124 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:52.124 | INFO     | __main__:<module>:344 - | end of epoch  30 | time:  3.46s | valid loss  5.65 | valid ppl   284.99
2025-10-20 19:45:52.186 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:52.597 | INFO     | __main__:train:295 - | epoch  31 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   290.76
2025-10-20 19:45:52.998 | INFO     | __main__:train:295 - | epoch  31 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.86
2025-10-20 19:45:53.398 | INFO     | __main__:train:295 - | epoch  31 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.26
2025-10-20 19:45:53.798 | INFO     | __main__:train:295 - | epoch  31 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.10
2025-10-20 19:45:54.202 | INFO     | __main__:train:295 - | epoch  31 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.66 | ppl   285.95
2025-10-20 19:45:54.602 | INFO     | __main__:train:295 - | epoch  31 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.99
2025-10-20 19:45:55.004 | INFO     | __main__:train:295 - | epoch  31 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   282.99
2025-10-20 19:45:55.404 | INFO     | __main__:train:295 - | epoch  31 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.14
2025-10-20 19:45:55.648 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:55.648 | INFO     | __main__:<module>:344 - | end of epoch  31 | time:  3.46s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:45:55.708 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:56.114 | INFO     | __main__:train:295 - | epoch  32 |   200/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.67 | ppl   290.74
2025-10-20 19:45:56.514 | INFO     | __main__:train:295 - | epoch  32 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.86
2025-10-20 19:45:56.916 | INFO     | __main__:train:295 - | epoch  32 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.25
2025-10-20 19:45:57.316 | INFO     | __main__:train:295 - | epoch  32 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.10
2025-10-20 19:45:57.716 | INFO     | __main__:train:295 - | epoch  32 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   285.95
2025-10-20 19:45:58.130 | INFO     | __main__:train:295 - | epoch  32 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.07 | loss  5.65 | ppl   284.98
2025-10-20 19:45:58.533 | INFO     | __main__:train:295 - | epoch  32 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   282.99
2025-10-20 19:45:58.935 | INFO     | __main__:train:295 - | epoch  32 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.14
2025-10-20 19:45:59.174 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:59.174 | INFO     | __main__:<module>:344 - | end of epoch  32 | time:  3.47s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:45:59.249 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:45:59.666 | INFO     | __main__:train:295 - | epoch  33 |   200/ 1632 batches | lr 0.02 | ms/batch  2.08 | loss  5.67 | ppl   290.74
2025-10-20 19:46:00.068 | INFO     | __main__:train:295 - | epoch  33 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.85
2025-10-20 19:46:00.468 | INFO     | __main__:train:295 - | epoch  33 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.25
2025-10-20 19:46:00.868 | INFO     | __main__:train:295 - | epoch  33 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.10
2025-10-20 19:46:01.268 | INFO     | __main__:train:295 - | epoch  33 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   285.95
2025-10-20 19:46:01.668 | INFO     | __main__:train:295 - | epoch  33 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:46:02.072 | INFO     | __main__:train:295 - | epoch  33 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   282.99
2025-10-20 19:46:02.474 | INFO     | __main__:train:295 - | epoch  33 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.14
2025-10-20 19:46:02.712 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:02.712 | INFO     | __main__:<module>:344 - | end of epoch  33 | time:  3.46s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:46:02.772 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:03.179 | INFO     | __main__:train:295 - | epoch  34 |   200/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.67 | ppl   290.73
2025-10-20 19:46:03.578 | INFO     | __main__:train:295 - | epoch  34 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.85
2025-10-20 19:46:03.980 | INFO     | __main__:train:295 - | epoch  34 |   600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.24
2025-10-20 19:46:04.385 | INFO     | __main__:train:295 - | epoch  34 |   800/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   284.09
2025-10-20 19:46:04.787 | INFO     | __main__:train:295 - | epoch  34 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   285.94
2025-10-20 19:46:05.188 | INFO     | __main__:train:295 - | epoch  34 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:46:05.588 | INFO     | __main__:train:295 - | epoch  34 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.98
2025-10-20 19:46:05.990 | INFO     | __main__:train:295 - | epoch  34 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.14
2025-10-20 19:46:06.228 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:06.228 | INFO     | __main__:<module>:344 - | end of epoch  34 | time:  3.46s | valid loss  5.65 | valid ppl   284.98
2025-10-20 19:46:06.288 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:06.698 | INFO     | __main__:train:295 - | epoch  35 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   290.72
2025-10-20 19:46:07.098 | INFO     | __main__:train:295 - | epoch  35 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.84
2025-10-20 19:46:07.498 | INFO     | __main__:train:295 - | epoch  35 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.24
2025-10-20 19:46:07.901 | INFO     | __main__:train:295 - | epoch  35 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.08
2025-10-20 19:46:08.303 | INFO     | __main__:train:295 - | epoch  35 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   285.94
2025-10-20 19:46:08.723 | INFO     | __main__:train:295 - | epoch  35 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.10 | loss  5.65 | ppl   284.98
2025-10-20 19:46:09.130 | INFO     | __main__:train:295 - | epoch  35 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   282.98
2025-10-20 19:46:09.530 | INFO     | __main__:train:295 - | epoch  35 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.14
2025-10-20 19:46:09.769 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:09.769 | INFO     | __main__:<module>:344 - | end of epoch  35 | time:  3.48s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:46:09.829 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:10.254 | INFO     | __main__:train:295 - | epoch  36 |   200/ 1632 batches | lr 0.02 | ms/batch  2.13 | loss  5.67 | ppl   290.71
2025-10-20 19:46:10.654 | INFO     | __main__:train:295 - | epoch  36 |   400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.84
2025-10-20 19:46:11.054 | INFO     | __main__:train:295 - | epoch  36 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.24
2025-10-20 19:46:11.454 | INFO     | __main__:train:295 - | epoch  36 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.08
2025-10-20 19:46:11.854 | INFO     | __main__:train:295 - | epoch  36 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   285.94
2025-10-20 19:46:12.254 | INFO     | __main__:train:295 - | epoch  36 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:46:12.654 | INFO     | __main__:train:295 - | epoch  36 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.99
2025-10-20 19:46:13.056 | INFO     | __main__:train:295 - | epoch  36 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.14
2025-10-20 19:46:13.307 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:13.307 | INFO     | __main__:<module>:344 - | end of epoch  36 | time:  3.48s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:46:13.383 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:13.794 | INFO     | __main__:train:295 - | epoch  37 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   290.71
2025-10-20 19:46:14.201 | INFO     | __main__:train:295 - | epoch  37 |   400/ 1632 batches | lr 0.02 | ms/batch  2.04 | loss  5.65 | ppl   284.84
2025-10-20 19:46:14.606 | INFO     | __main__:train:295 - | epoch  37 |   600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.23
2025-10-20 19:46:15.008 | INFO     | __main__:train:295 - | epoch  37 |   800/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.08
2025-10-20 19:46:15.408 | INFO     | __main__:train:295 - | epoch  37 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.66 | ppl   285.93
2025-10-20 19:46:15.808 | INFO     | __main__:train:295 - | epoch  37 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.98
2025-10-20 19:46:16.208 | INFO     | __main__:train:295 - | epoch  37 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.99
2025-10-20 19:46:16.608 | INFO     | __main__:train:295 - | epoch  37 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.14
2025-10-20 19:46:16.849 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:16.849 | INFO     | __main__:<module>:344 - | end of epoch  37 | time:  3.47s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:46:16.909 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:17.324 | INFO     | __main__:train:295 - | epoch  38 |   200/ 1632 batches | lr 0.02 | ms/batch  2.07 | loss  5.67 | ppl   290.71
2025-10-20 19:46:17.726 | INFO     | __main__:train:295 - | epoch  38 |   400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   284.83
2025-10-20 19:46:18.127 | INFO     | __main__:train:295 - | epoch  38 |   600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.23
2025-10-20 19:46:18.528 | INFO     | __main__:train:295 - | epoch  38 |   800/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.08
2025-10-20 19:46:18.929 | INFO     | __main__:train:295 - | epoch  38 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.66 | ppl   285.93
2025-10-20 19:46:19.330 | INFO     | __main__:train:295 - | epoch  38 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.97
2025-10-20 19:46:19.730 | INFO     | __main__:train:295 - | epoch  38 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   282.98
2025-10-20 19:46:20.130 | INFO     | __main__:train:295 - | epoch  38 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.00 | loss  5.65 | ppl   284.14
2025-10-20 19:46:20.369 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:20.369 | INFO     | __main__:<module>:344 - | end of epoch  38 | time:  3.46s | valid loss  5.65 | valid ppl   284.97
2025-10-20 19:46:20.369 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:46:20.369 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.0048828125
2025-10-20 19:46:20.400 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:20.829 | INFO     | __main__:train:295 - | epoch  39 |   200/ 1632 batches | lr 0.00 | ms/batch  2.14 | loss  5.67 | ppl   290.71
2025-10-20 19:46:21.230 | INFO     | __main__:train:295 - | epoch  39 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.83
2025-10-20 19:46:21.632 | INFO     | __main__:train:295 - | epoch  39 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.23
2025-10-20 19:46:22.034 | INFO     | __main__:train:295 - | epoch  39 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.07
2025-10-20 19:46:22.449 | INFO     | __main__:train:295 - | epoch  39 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.07 | loss  5.66 | ppl   285.91
2025-10-20 19:46:22.852 | INFO     | __main__:train:295 - | epoch  39 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.95
2025-10-20 19:46:23.252 | INFO     | __main__:train:295 - | epoch  39 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:23.653 | INFO     | __main__:train:295 - | epoch  39 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:23.894 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:23.894 | INFO     | __main__:<module>:344 - | end of epoch  39 | time:  3.49s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:23.970 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:24.383 | INFO     | __main__:train:295 - | epoch  40 |   200/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.67 | ppl   290.70
2025-10-20 19:46:24.783 | INFO     | __main__:train:295 - | epoch  40 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.82
2025-10-20 19:46:25.184 | INFO     | __main__:train:295 - | epoch  40 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.22
2025-10-20 19:46:25.584 | INFO     | __main__:train:295 - | epoch  40 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.07
2025-10-20 19:46:25.986 | INFO     | __main__:train:295 - | epoch  40 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   285.91
2025-10-20 19:46:26.405 | INFO     | __main__:train:295 - | epoch  40 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.09 | loss  5.65 | ppl   284.95
2025-10-20 19:46:26.806 | INFO     | __main__:train:295 - | epoch  40 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   282.95
2025-10-20 19:46:27.206 | INFO     | __main__:train:295 - | epoch  40 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:27.453 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:27.453 | INFO     | __main__:<module>:344 - | end of epoch  40 | time:  3.48s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:27.512 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:27.930 | INFO     | __main__:train:295 - | epoch  41 |   200/ 1632 batches | lr 0.00 | ms/batch  2.09 | loss  5.67 | ppl   290.71
2025-10-20 19:46:28.330 | INFO     | __main__:train:295 - | epoch  41 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.82
2025-10-20 19:46:28.730 | INFO     | __main__:train:295 - | epoch  41 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.23
2025-10-20 19:46:29.129 | INFO     | __main__:train:295 - | epoch  41 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.07
2025-10-20 19:46:29.530 | INFO     | __main__:train:295 - | epoch  41 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.91
2025-10-20 19:46:29.930 | INFO     | __main__:train:295 - | epoch  41 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:30.332 | INFO     | __main__:train:295 - | epoch  41 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   282.96
2025-10-20 19:46:30.732 | INFO     | __main__:train:295 - | epoch  41 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:30.971 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:30.971 | INFO     | __main__:<module>:344 - | end of epoch  41 | time:  3.46s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:31.030 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:31.438 | INFO     | __main__:train:295 - | epoch  42 |   200/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.67 | ppl   290.70
2025-10-20 19:46:31.838 | INFO     | __main__:train:295 - | epoch  42 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.82
2025-10-20 19:46:32.237 | INFO     | __main__:train:295 - | epoch  42 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.22
2025-10-20 19:46:32.638 | INFO     | __main__:train:295 - | epoch  42 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.06
2025-10-20 19:46:33.054 | INFO     | __main__:train:295 - | epoch  42 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.66 | ppl   285.91
2025-10-20 19:46:33.455 | INFO     | __main__:train:295 - | epoch  42 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.94
2025-10-20 19:46:33.854 | INFO     | __main__:train:295 - | epoch  42 |  1400/ 1632 batches | lr 0.00 | ms/batch  1.99 | loss  5.65 | ppl   282.96
2025-10-20 19:46:34.270 | INFO     | __main__:train:295 - | epoch  42 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.65 | ppl   284.12
2025-10-20 19:46:34.520 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:34.521 | INFO     | __main__:<module>:344 - | end of epoch  42 | time:  3.49s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:34.579 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:35.008 | INFO     | __main__:train:295 - | epoch  43 |   200/ 1632 batches | lr 0.00 | ms/batch  2.14 | loss  5.67 | ppl   290.70
2025-10-20 19:46:35.411 | INFO     | __main__:train:295 - | epoch  43 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.82
2025-10-20 19:46:35.817 | INFO     | __main__:train:295 - | epoch  43 |   600/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.21
2025-10-20 19:46:36.218 | INFO     | __main__:train:295 - | epoch  43 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.07
2025-10-20 19:46:36.618 | INFO     | __main__:train:295 - | epoch  43 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.91
2025-10-20 19:46:37.018 | INFO     | __main__:train:295 - | epoch  43 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:37.418 | INFO     | __main__:train:295 - | epoch  43 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:37.818 | INFO     | __main__:train:295 - | epoch  43 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:38.054 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:38.054 | INFO     | __main__:<module>:344 - | end of epoch  43 | time:  3.48s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:38.132 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:38.544 | INFO     | __main__:train:295 - | epoch  44 |   200/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.67 | ppl   290.70
2025-10-20 19:46:38.944 | INFO     | __main__:train:295 - | epoch  44 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.81
2025-10-20 19:46:39.348 | INFO     | __main__:train:295 - | epoch  44 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.22
2025-10-20 19:46:39.750 | INFO     | __main__:train:295 - | epoch  44 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.06
2025-10-20 19:46:40.150 | INFO     | __main__:train:295 - | epoch  44 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.91
2025-10-20 19:46:40.550 | INFO     | __main__:train:295 - | epoch  44 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:40.950 | INFO     | __main__:train:295 - | epoch  44 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:41.350 | INFO     | __main__:train:295 - | epoch  44 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.13
2025-10-20 19:46:41.588 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:41.588 | INFO     | __main__:<module>:344 - | end of epoch  44 | time:  3.46s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:41.648 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:42.054 | INFO     | __main__:train:295 - | epoch  45 |   200/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.67 | ppl   290.70
2025-10-20 19:46:42.457 | INFO     | __main__:train:295 - | epoch  45 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.81
2025-10-20 19:46:42.860 | INFO     | __main__:train:295 - | epoch  45 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.21
2025-10-20 19:46:43.260 | INFO     | __main__:train:295 - | epoch  45 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.07
2025-10-20 19:46:43.661 | INFO     | __main__:train:295 - | epoch  45 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.91
2025-10-20 19:46:44.062 | INFO     | __main__:train:295 - | epoch  45 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.94
2025-10-20 19:46:44.465 | INFO     | __main__:train:295 - | epoch  45 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   282.96
2025-10-20 19:46:44.866 | INFO     | __main__:train:295 - | epoch  45 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.12
2025-10-20 19:46:45.110 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:45.110 | INFO     | __main__:<module>:344 - | end of epoch  45 | time:  3.46s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:45.171 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:45.578 | INFO     | __main__:train:295 - | epoch  46 |   200/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.67 | ppl   290.69
2025-10-20 19:46:45.980 | INFO     | __main__:train:295 - | epoch  46 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.81
2025-10-20 19:46:46.380 | INFO     | __main__:train:295 - | epoch  46 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:46:46.780 | INFO     | __main__:train:295 - | epoch  46 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.06
2025-10-20 19:46:47.180 | INFO     | __main__:train:295 - | epoch  46 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.90
2025-10-20 19:46:47.580 | INFO     | __main__:train:295 - | epoch  46 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:47.980 | INFO     | __main__:train:295 - | epoch  46 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:48.380 | INFO     | __main__:train:295 - | epoch  46 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:48.622 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:48.623 | INFO     | __main__:<module>:344 - | end of epoch  46 | time:  3.45s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:48.685 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:49.158 | INFO     | __main__:train:295 - | epoch  47 |   200/ 1632 batches | lr 0.00 | ms/batch  2.37 | loss  5.67 | ppl   290.69
2025-10-20 19:46:49.562 | INFO     | __main__:train:295 - | epoch  47 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.81
2025-10-20 19:46:49.964 | INFO     | __main__:train:295 - | epoch  47 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.21
2025-10-20 19:46:50.364 | INFO     | __main__:train:295 - | epoch  47 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.05
2025-10-20 19:46:50.766 | INFO     | __main__:train:295 - | epoch  47 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   285.91
2025-10-20 19:46:51.166 | INFO     | __main__:train:295 - | epoch  47 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:51.566 | INFO     | __main__:train:295 - | epoch  47 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:51.966 | INFO     | __main__:train:295 - | epoch  47 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:52.208 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:52.208 | INFO     | __main__:<module>:344 - | end of epoch  47 | time:  3.52s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:52.208 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:46:52.208 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.001220703125
2025-10-20 19:46:52.260 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:52.666 | INFO     | __main__:train:295 - | epoch  48 |   200/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.67 | ppl   290.70
2025-10-20 19:46:53.068 | INFO     | __main__:train:295 - | epoch  48 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.81
2025-10-20 19:46:53.468 | INFO     | __main__:train:295 - | epoch  48 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:46:53.868 | INFO     | __main__:train:295 - | epoch  48 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.06
2025-10-20 19:46:54.268 | INFO     | __main__:train:295 - | epoch  48 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.90
2025-10-20 19:46:54.668 | INFO     | __main__:train:295 - | epoch  48 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.94
2025-10-20 19:46:55.069 | INFO     | __main__:train:295 - | epoch  48 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:46:55.472 | INFO     | __main__:train:295 - | epoch  48 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.12
2025-10-20 19:46:55.712 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:55.713 | INFO     | __main__:<module>:344 - | end of epoch  48 | time:  3.45s | valid loss  5.65 | valid ppl   284.96
2025-10-20 19:46:55.772 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:56.195 | INFO     | __main__:train:295 - | epoch  49 |   200/ 1632 batches | lr 0.00 | ms/batch  2.11 | loss  5.67 | ppl   290.69
2025-10-20 19:46:56.596 | INFO     | __main__:train:295 - | epoch  49 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.81
2025-10-20 19:46:56.996 | INFO     | __main__:train:295 - | epoch  49 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:46:57.396 | INFO     | __main__:train:295 - | epoch  49 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.06
2025-10-20 19:46:57.797 | INFO     | __main__:train:295 - | epoch  49 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.90
2025-10-20 19:46:58.197 | INFO     | __main__:train:295 - | epoch  49 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.95
2025-10-20 19:46:58.597 | INFO     | __main__:train:295 - | epoch  49 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.95
2025-10-20 19:46:58.998 | INFO     | __main__:train:295 - | epoch  49 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:46:59.237 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:59.237 | INFO     | __main__:<module>:344 - | end of epoch  49 | time:  3.46s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:46:59.297 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:46:59.743 | INFO     | __main__:train:295 - | epoch  50 |   200/ 1632 batches | lr 0.00 | ms/batch  2.23 | loss  5.67 | ppl   290.69
2025-10-20 19:47:00.144 | INFO     | __main__:train:295 - | epoch  50 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.80
2025-10-20 19:47:00.544 | INFO     | __main__:train:295 - | epoch  50 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:47:00.944 | INFO     | __main__:train:295 - | epoch  50 |   800/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.06
2025-10-20 19:47:01.344 | INFO     | __main__:train:295 - | epoch  50 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.91
2025-10-20 19:47:01.744 | INFO     | __main__:train:295 - | epoch  50 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.94
2025-10-20 19:47:02.147 | INFO     | __main__:train:295 - | epoch  50 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   282.95
2025-10-20 19:47:02.547 | INFO     | __main__:train:295 - | epoch  50 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:47:02.789 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:02.789 | INFO     | __main__:<module>:344 - | end of epoch  50 | time:  3.49s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:47:02.849 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:03.254 | INFO     | __main__:train:295 - | epoch  51 |   200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.67 | ppl   290.69
2025-10-20 19:47:03.654 | INFO     | __main__:train:295 - | epoch  51 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.81
2025-10-20 19:47:04.054 | INFO     | __main__:train:295 - | epoch  51 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:47:04.456 | INFO     | __main__:train:295 - | epoch  51 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.06
2025-10-20 19:47:04.856 | INFO     | __main__:train:295 - | epoch  51 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.66 | ppl   285.90
2025-10-20 19:47:05.256 | INFO     | __main__:train:295 - | epoch  51 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.94
2025-10-20 19:47:05.656 | INFO     | __main__:train:295 - | epoch  51 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.95
2025-10-20 19:47:06.058 | INFO     | __main__:train:295 - | epoch  51 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.12
2025-10-20 19:47:06.294 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:06.294 | INFO     | __main__:<module>:344 - | end of epoch  51 | time:  3.44s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:47:06.370 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:06.778 | INFO     | __main__:train:295 - | epoch  52 |   200/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.67 | ppl   290.68
2025-10-20 19:47:07.177 | INFO     | __main__:train:295 - | epoch  52 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.80
2025-10-20 19:47:07.580 | INFO     | __main__:train:295 - | epoch  52 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.22
2025-10-20 19:47:07.982 | INFO     | __main__:train:295 - | epoch  52 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.06
2025-10-20 19:47:08.384 | INFO     | __main__:train:295 - | epoch  52 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.66 | ppl   285.90
2025-10-20 19:47:08.787 | INFO     | __main__:train:295 - | epoch  52 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.95
2025-10-20 19:47:09.190 | INFO     | __main__:train:295 - | epoch  52 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   282.96
2025-10-20 19:47:09.590 | INFO     | __main__:train:295 - | epoch  52 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.12
2025-10-20 19:47:09.827 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:09.827 | INFO     | __main__:<module>:344 - | end of epoch  52 | time:  3.46s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:47:09.827 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:47:09.827 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.00030517578125
2025-10-20 19:47:09.858 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:10.268 | INFO     | __main__:train:295 - | epoch  53 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.68
2025-10-20 19:47:10.668 | INFO     | __main__:train:295 - | epoch  53 |   400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.80
2025-10-20 19:47:11.069 | INFO     | __main__:train:295 - | epoch  53 |   600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.21
2025-10-20 19:47:11.474 | INFO     | __main__:train:295 - | epoch  53 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.06
2025-10-20 19:47:11.877 | INFO     | __main__:train:295 - | epoch  53 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.66 | ppl   285.90
2025-10-20 19:47:12.278 | INFO     | __main__:train:295 - | epoch  53 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.94
2025-10-20 19:47:12.678 | INFO     | __main__:train:295 - | epoch  53 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   282.96
2025-10-20 19:47:13.078 | INFO     | __main__:train:295 - | epoch  53 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.00 | loss  5.65 | ppl   284.11
2025-10-20 19:47:13.319 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:13.319 | INFO     | __main__:<module>:344 - | end of epoch  53 | time:  3.46s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:47:13.319 | INFO     | __main__:<module>:367 - | epochs since loss improved: 2
2025-10-20 19:47:13.319 | INFO     | __main__:<module>:368 - | reducing learning rate to 7.62939453125e-05
2025-10-20 19:47:13.350 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:37.760 | INFO     | __main__:<module>:76 - Using GPU ID 0
2025-10-20 19:47:37.860 | INFO     | __main__:<module>:82 - Loading data
2025-10-20 19:47:37.860 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-20 19:47:37.867 | INFO     | corpus:__init__:86 - Loaded dictionary from data/CHILDES/train_dict_a7be993a.cached
2025-10-20 19:47:37.867 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/train.txt.original...
2025-10-20 19:47:37.877 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/valid.txt.original...
2025-10-20 19:47:37.878 | INFO     | corpus:tokenize:146 - Tokenizing data/CHILDES/test.txt.original...
2025-10-20 19:47:37.879 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-20 19:47:37.879 | INFO     | __main__:<module>:88 - ( 0.02 )
2025-10-20 19:47:37.879 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-20 19:47:37.879 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-20 19:47:37.883 | INFO     | __main__:<module>:128 - Building the model
2025-10-20 19:47:37.924 | INFO     | __main__:<module>:315 - Running Transformer with args: {'data': 'data/CHILDES', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': True, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-20 19:47:37.924 | INFO     | __main__:<module>:317 - Transformer id: d25ef8a2
2025-10-20 19:47:38.439 | INFO     | __main__:train:295 - | epoch   0 |   200/ 1632 batches | lr 20.00 | ms/batch  2.57 | loss  9.25 | ppl 10400.46
2025-10-20 19:47:38.842 | INFO     | __main__:train:295 - | epoch   0 |   400/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  8.40 | ppl  4439.27
2025-10-20 19:47:39.243 | INFO     | __main__:train:295 - | epoch   0 |   600/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.91 | ppl  2725.15
2025-10-20 19:47:39.644 | INFO     | __main__:train:295 - | epoch   0 |   800/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  7.81 | ppl  2471.76
2025-10-20 19:47:40.047 | INFO     | __main__:train:295 - | epoch   0 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.01 | loss  7.92 | ppl  2747.26
2025-10-20 19:47:40.448 | INFO     | __main__:train:295 - | epoch   0 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.86 | ppl  2580.68
2025-10-20 19:47:40.849 | INFO     | __main__:train:295 - | epoch   0 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.00 | loss  7.74 | ppl  2298.06
2025-10-20 19:47:41.253 | INFO     | __main__:train:295 - | epoch   0 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.02 | loss  7.68 | ppl  2167.91
2025-10-20 19:47:41.497 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:41.498 | INFO     | __main__:<module>:344 - | end of epoch   0 | time:  3.57s | valid loss  6.28 | valid ppl   533.54
2025-10-20 19:47:41.577 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:41.986 | INFO     | __main__:train:295 - | epoch   1 |   200/ 1632 batches | lr 20.00 | ms/batch  2.05 | loss  7.61 | ppl  2021.81
2025-10-20 19:47:42.392 | INFO     | __main__:train:295 - | epoch   1 |   400/ 1632 batches | lr 20.00 | ms/batch  2.03 | loss  7.64 | ppl  2070.27
2025-10-20 19:47:42.797 | INFO     | __main__:train:295 - | epoch   1 |   600/ 1632 batches | lr 20.00 | ms/batch  2.02 | loss  7.72 | ppl  2247.23
2025-10-20 19:47:43.202 | INFO     | __main__:train:295 - | epoch   1 |   800/ 1632 batches | lr 20.00 | ms/batch  2.02 | loss  7.55 | ppl  1906.12
2025-10-20 19:47:43.608 | INFO     | __main__:train:295 - | epoch   1 |  1000/ 1632 batches | lr 20.00 | ms/batch  2.03 | loss  7.62 | ppl  2041.85
2025-10-20 19:47:44.013 | INFO     | __main__:train:295 - | epoch   1 |  1200/ 1632 batches | lr 20.00 | ms/batch  2.02 | loss  7.81 | ppl  2453.88
2025-10-20 19:47:44.429 | INFO     | __main__:train:295 - | epoch   1 |  1400/ 1632 batches | lr 20.00 | ms/batch  2.08 | loss  7.52 | ppl  1837.86
2025-10-20 19:47:44.834 | INFO     | __main__:train:295 - | epoch   1 |  1600/ 1632 batches | lr 20.00 | ms/batch  2.02 | loss  7.50 | ppl  1816.71
2025-10-20 19:47:45.077 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:45.077 | INFO     | __main__:<module>:344 - | end of epoch   1 | time:  3.50s | valid loss  7.15 | valid ppl  1276.90
2025-10-20 19:47:45.077 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:47:45.077 | INFO     | __main__:<module>:368 - | reducing learning rate to 5.0
2025-10-20 19:47:45.115 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:45.528 | INFO     | __main__:train:295 - | epoch   2 |   200/ 1632 batches | lr 5.00 | ms/batch  2.07 | loss  5.79 | ppl   326.71
2025-10-20 19:47:45.934 | INFO     | __main__:train:295 - | epoch   2 |   400/ 1632 batches | lr 5.00 | ms/batch  2.03 | loss  5.75 | ppl   315.05
2025-10-20 19:47:46.338 | INFO     | __main__:train:295 - | epoch   2 |   600/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.74 | ppl   311.00
2025-10-20 19:47:46.742 | INFO     | __main__:train:295 - | epoch   2 |   800/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.74 | ppl   310.06
2025-10-20 19:47:47.147 | INFO     | __main__:train:295 - | epoch   2 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.74 | ppl   310.34
2025-10-20 19:47:47.549 | INFO     | __main__:train:295 - | epoch   2 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.72 | ppl   306.15
2025-10-20 19:47:47.953 | INFO     | __main__:train:295 - | epoch   2 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.72 | ppl   304.30
2025-10-20 19:47:48.357 | INFO     | __main__:train:295 - | epoch   2 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.72 | ppl   304.11
2025-10-20 19:47:48.601 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:48.601 | INFO     | __main__:<module>:344 - | end of epoch   2 | time:  3.49s | valid loss  5.69 | valid ppl   295.37
2025-10-20 19:47:48.664 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:49.076 | INFO     | __main__:train:295 - | epoch   3 |   200/ 1632 batches | lr 5.00 | ms/batch  2.06 | loss  5.73 | ppl   309.11
2025-10-20 19:47:49.482 | INFO     | __main__:train:295 - | epoch   3 |   400/ 1632 batches | lr 5.00 | ms/batch  2.03 | loss  5.71 | ppl   301.56
2025-10-20 19:47:49.886 | INFO     | __main__:train:295 - | epoch   3 |   600/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.71 | ppl   300.58
2025-10-20 19:47:50.289 | INFO     | __main__:train:295 - | epoch   3 |   800/ 1632 batches | lr 5.00 | ms/batch  2.01 | loss  5.70 | ppl   300.15
2025-10-20 19:47:50.694 | INFO     | __main__:train:295 - | epoch   3 |  1000/ 1632 batches | lr 5.00 | ms/batch  2.03 | loss  5.71 | ppl   301.57
2025-10-20 19:47:51.098 | INFO     | __main__:train:295 - | epoch   3 |  1200/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.70 | ppl   299.06
2025-10-20 19:47:51.506 | INFO     | __main__:train:295 - | epoch   3 |  1400/ 1632 batches | lr 5.00 | ms/batch  2.04 | loss  5.70 | ppl   297.53
2025-10-20 19:47:51.911 | INFO     | __main__:train:295 - | epoch   3 |  1600/ 1632 batches | lr 5.00 | ms/batch  2.02 | loss  5.70 | ppl   297.41
2025-10-20 19:47:52.161 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:52.162 | INFO     | __main__:<module>:344 - | end of epoch   3 | time:  3.50s | valid loss  5.78 | valid ppl   324.00
2025-10-20 19:47:52.162 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:47:52.162 | INFO     | __main__:<module>:368 - | reducing learning rate to 1.25
2025-10-20 19:47:52.193 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:52.605 | INFO     | __main__:train:295 - | epoch   4 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.70 | ppl   297.64
2025-10-20 19:47:53.010 | INFO     | __main__:train:295 - | epoch   4 |   400/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.67 | ppl   290.61
2025-10-20 19:47:53.414 | INFO     | __main__:train:295 - | epoch   4 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   289.86
2025-10-20 19:47:53.816 | INFO     | __main__:train:295 - | epoch   4 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.67 | ppl   289.61
2025-10-20 19:47:54.220 | INFO     | __main__:train:295 - | epoch   4 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   291.35
2025-10-20 19:47:54.625 | INFO     | __main__:train:295 - | epoch   4 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   290.01
2025-10-20 19:47:55.029 | INFO     | __main__:train:295 - | epoch   4 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.79
2025-10-20 19:47:55.432 | INFO     | __main__:train:295 - | epoch   4 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   288.87
2025-10-20 19:47:55.676 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:55.676 | INFO     | __main__:<module>:344 - | end of epoch   4 | time:  3.48s | valid loss  5.67 | valid ppl   289.80
2025-10-20 19:47:55.745 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:56.156 | INFO     | __main__:train:295 - | epoch   5 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.69 | ppl   295.50
2025-10-20 19:47:56.560 | INFO     | __main__:train:295 - | epoch   5 |   400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   289.00
2025-10-20 19:47:56.964 | INFO     | __main__:train:295 - | epoch   5 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   288.44
2025-10-20 19:47:57.367 | INFO     | __main__:train:295 - | epoch   5 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.25
2025-10-20 19:47:57.771 | INFO     | __main__:train:295 - | epoch   5 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   290.11
2025-10-20 19:47:58.174 | INFO     | __main__:train:295 - | epoch   5 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.67 | ppl   288.93
2025-10-20 19:47:58.577 | INFO     | __main__:train:295 - | epoch   5 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.76
2025-10-20 19:47:58.979 | INFO     | __main__:train:295 - | epoch   5 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.98
2025-10-20 19:47:59.225 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:59.225 | INFO     | __main__:<module>:344 - | end of epoch   5 | time:  3.48s | valid loss  5.67 | valid ppl   289.09
2025-10-20 19:47:59.299 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:47:59.712 | INFO     | __main__:train:295 - | epoch   6 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.69 | ppl   294.47
2025-10-20 19:48:00.115 | INFO     | __main__:train:295 - | epoch   6 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.14
2025-10-20 19:48:00.518 | INFO     | __main__:train:295 - | epoch   6 |   600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.62
2025-10-20 19:48:00.922 | INFO     | __main__:train:295 - | epoch   6 |   800/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.45
2025-10-20 19:48:01.325 | INFO     | __main__:train:295 - | epoch   6 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.67 | ppl   289.33
2025-10-20 19:48:01.728 | INFO     | __main__:train:295 - | epoch   6 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.22
2025-10-20 19:48:02.130 | INFO     | __main__:train:295 - | epoch   6 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.08
2025-10-20 19:48:02.533 | INFO     | __main__:train:295 - | epoch   6 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.36
2025-10-20 19:48:02.779 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:02.779 | INFO     | __main__:<module>:344 - | end of epoch   6 | time:  3.48s | valid loss  5.67 | valid ppl   288.64
2025-10-20 19:48:02.841 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:03.251 | INFO     | __main__:train:295 - | epoch   7 |   200/ 1632 batches | lr 1.25 | ms/batch  2.05 | loss  5.68 | ppl   293.80
2025-10-20 19:48:03.659 | INFO     | __main__:train:295 - | epoch   7 |   400/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.66 | ppl   287.58
2025-10-20 19:48:04.064 | INFO     | __main__:train:295 - | epoch   7 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.04
2025-10-20 19:48:04.468 | INFO     | __main__:train:295 - | epoch   7 |   800/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.86
2025-10-20 19:48:04.873 | INFO     | __main__:train:295 - | epoch   7 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.67 | ppl   288.75
2025-10-20 19:48:05.277 | INFO     | __main__:train:295 - | epoch   7 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.71
2025-10-20 19:48:05.680 | INFO     | __main__:train:295 - | epoch   7 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   285.60
2025-10-20 19:48:06.083 | INFO     | __main__:train:295 - | epoch   7 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.92
2025-10-20 19:48:06.332 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:06.332 | INFO     | __main__:<module>:344 - | end of epoch   7 | time:  3.49s | valid loss  5.66 | valid ppl   288.35
2025-10-20 19:48:06.415 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:06.830 | INFO     | __main__:train:295 - | epoch   8 |   200/ 1632 batches | lr 1.25 | ms/batch  2.07 | loss  5.68 | ppl   293.34
2025-10-20 19:48:07.234 | INFO     | __main__:train:295 - | epoch   8 |   400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.15
2025-10-20 19:48:07.637 | INFO     | __main__:train:295 - | epoch   8 |   600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.60
2025-10-20 19:48:08.040 | INFO     | __main__:train:295 - | epoch   8 |   800/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.46
2025-10-20 19:48:08.443 | INFO     | __main__:train:295 - | epoch   8 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.34
2025-10-20 19:48:08.854 | INFO     | __main__:train:295 - | epoch   8 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.66 | ppl   287.33
2025-10-20 19:48:09.257 | INFO     | __main__:train:295 - | epoch   8 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.24
2025-10-20 19:48:09.661 | INFO     | __main__:train:295 - | epoch   8 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.59
2025-10-20 19:48:09.908 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:09.908 | INFO     | __main__:<module>:344 - | end of epoch   8 | time:  3.49s | valid loss  5.66 | valid ppl   288.11
2025-10-20 19:48:09.984 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:10.396 | INFO     | __main__:train:295 - | epoch   9 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.68 | ppl   292.99
2025-10-20 19:48:10.799 | INFO     | __main__:train:295 - | epoch   9 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.84
2025-10-20 19:48:11.203 | INFO     | __main__:train:295 - | epoch   9 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.31
2025-10-20 19:48:11.605 | INFO     | __main__:train:295 - | epoch   9 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.15
2025-10-20 19:48:12.008 | INFO     | __main__:train:295 - | epoch   9 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   288.04
2025-10-20 19:48:12.412 | INFO     | __main__:train:295 - | epoch   9 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.04
2025-10-20 19:48:12.814 | INFO     | __main__:train:295 - | epoch   9 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   284.98
2025-10-20 19:48:13.228 | INFO     | __main__:train:295 - | epoch   9 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.07 | loss  5.66 | ppl   286.30
2025-10-20 19:48:13.470 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:13.470 | INFO     | __main__:<module>:344 - | end of epoch   9 | time:  3.49s | valid loss  5.66 | valid ppl   288.09
2025-10-20 19:48:13.537 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:13.948 | INFO     | __main__:train:295 - | epoch  10 |   200/ 1632 batches | lr 1.25 | ms/batch  2.05 | loss  5.68 | ppl   292.71
2025-10-20 19:48:14.351 | INFO     | __main__:train:295 - | epoch  10 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.61
2025-10-20 19:48:14.755 | INFO     | __main__:train:295 - | epoch  10 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.07
2025-10-20 19:48:15.160 | INFO     | __main__:train:295 - | epoch  10 |   800/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.66 | ppl   285.91
2025-10-20 19:48:15.574 | INFO     | __main__:train:295 - | epoch  10 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.07 | loss  5.66 | ppl   287.79
2025-10-20 19:48:15.977 | INFO     | __main__:train:295 - | epoch  10 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.81
2025-10-20 19:48:16.393 | INFO     | __main__:train:295 - | epoch  10 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.08 | loss  5.65 | ppl   284.76
2025-10-20 19:48:16.797 | INFO     | __main__:train:295 - | epoch  10 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.11
2025-10-20 19:48:17.041 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:17.041 | INFO     | __main__:<module>:344 - | end of epoch  10 | time:  3.50s | valid loss  5.66 | valid ppl   287.99
2025-10-20 19:48:17.106 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:17.524 | INFO     | __main__:train:295 - | epoch  11 |   200/ 1632 batches | lr 1.25 | ms/batch  2.09 | loss  5.68 | ppl   292.51
2025-10-20 19:48:17.929 | INFO     | __main__:train:295 - | epoch  11 |   400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.42
2025-10-20 19:48:18.333 | INFO     | __main__:train:295 - | epoch  11 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   285.88
2025-10-20 19:48:18.737 | INFO     | __main__:train:295 - | epoch  11 |   800/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   285.71
2025-10-20 19:48:19.139 | INFO     | __main__:train:295 - | epoch  11 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   287.60
2025-10-20 19:48:19.542 | INFO     | __main__:train:295 - | epoch  11 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.63
2025-10-20 19:48:19.945 | INFO     | __main__:train:295 - | epoch  11 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   284.59
2025-10-20 19:48:20.348 | INFO     | __main__:train:295 - | epoch  11 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   285.92
2025-10-20 19:48:20.589 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:20.589 | INFO     | __main__:<module>:344 - | end of epoch  11 | time:  3.48s | valid loss  5.66 | valid ppl   287.88
2025-10-20 19:48:20.654 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:21.065 | INFO     | __main__:train:295 - | epoch  12 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.68 | ppl   292.34
2025-10-20 19:48:21.467 | INFO     | __main__:train:295 - | epoch  12 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.26
2025-10-20 19:48:21.871 | INFO     | __main__:train:295 - | epoch  12 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   285.71
2025-10-20 19:48:22.273 | INFO     | __main__:train:295 - | epoch  12 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.56
2025-10-20 19:48:22.676 | INFO     | __main__:train:295 - | epoch  12 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.42
2025-10-20 19:48:23.079 | INFO     | __main__:train:295 - | epoch  12 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   286.49
2025-10-20 19:48:23.484 | INFO     | __main__:train:295 - | epoch  12 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.65 | ppl   284.43
2025-10-20 19:48:23.887 | INFO     | __main__:train:295 - | epoch  12 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   285.78
2025-10-20 19:48:24.133 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:24.133 | INFO     | __main__:<module>:344 - | end of epoch  12 | time:  3.48s | valid loss  5.66 | valid ppl   287.84
2025-10-20 19:48:24.211 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:24.622 | INFO     | __main__:train:295 - | epoch  13 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.68 | ppl   292.17
2025-10-20 19:48:25.025 | INFO     | __main__:train:295 - | epoch  13 |   400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.13
2025-10-20 19:48:25.428 | INFO     | __main__:train:295 - | epoch  13 |   600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.57
2025-10-20 19:48:25.831 | INFO     | __main__:train:295 - | epoch  13 |   800/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.43
2025-10-20 19:48:26.236 | INFO     | __main__:train:295 - | epoch  13 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.29
2025-10-20 19:48:26.640 | INFO     | __main__:train:295 - | epoch  13 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   286.34
2025-10-20 19:48:27.045 | INFO     | __main__:train:295 - | epoch  13 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   284.33
2025-10-20 19:48:27.450 | INFO     | __main__:train:295 - | epoch  13 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   285.65
2025-10-20 19:48:27.696 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:27.696 | INFO     | __main__:<module>:344 - | end of epoch  13 | time:  3.48s | valid loss  5.66 | valid ppl   287.79
2025-10-20 19:48:27.759 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:28.169 | INFO     | __main__:train:295 - | epoch  14 |   200/ 1632 batches | lr 1.25 | ms/batch  2.05 | loss  5.68 | ppl   292.06
2025-10-20 19:48:28.575 | INFO     | __main__:train:295 - | epoch  14 |   400/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.66 | ppl   286.01
2025-10-20 19:48:28.978 | INFO     | __main__:train:295 - | epoch  14 |   600/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   285.46
2025-10-20 19:48:29.386 | INFO     | __main__:train:295 - | epoch  14 |   800/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.65 | ppl   285.29
2025-10-20 19:48:29.790 | INFO     | __main__:train:295 - | epoch  14 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.66 | ppl   287.16
2025-10-20 19:48:30.199 | INFO     | __main__:train:295 - | epoch  14 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.66 | ppl   286.23
2025-10-20 19:48:30.603 | INFO     | __main__:train:295 - | epoch  14 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.02 | loss  5.65 | ppl   284.22
2025-10-20 19:48:31.009 | INFO     | __main__:train:295 - | epoch  14 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.65 | ppl   285.54
2025-10-20 19:48:31.252 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:31.252 | INFO     | __main__:<module>:344 - | end of epoch  14 | time:  3.49s | valid loss  5.66 | valid ppl   287.73
2025-10-20 19:48:31.317 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:31.728 | INFO     | __main__:train:295 - | epoch  15 |   200/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.68 | ppl   291.95
2025-10-20 19:48:32.131 | INFO     | __main__:train:295 - | epoch  15 |   400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.66 | ppl   285.91
2025-10-20 19:48:32.539 | INFO     | __main__:train:295 - | epoch  15 |   600/ 1632 batches | lr 1.25 | ms/batch  2.04 | loss  5.65 | ppl   285.36
2025-10-20 19:48:32.944 | INFO     | __main__:train:295 - | epoch  15 |   800/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.65 | ppl   285.19
2025-10-20 19:48:33.356 | INFO     | __main__:train:295 - | epoch  15 |  1000/ 1632 batches | lr 1.25 | ms/batch  2.06 | loss  5.66 | ppl   287.05
2025-10-20 19:48:33.761 | INFO     | __main__:train:295 - | epoch  15 |  1200/ 1632 batches | lr 1.25 | ms/batch  2.03 | loss  5.66 | ppl   286.13
2025-10-20 19:48:34.164 | INFO     | __main__:train:295 - | epoch  15 |  1400/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   284.13
2025-10-20 19:48:34.567 | INFO     | __main__:train:295 - | epoch  15 |  1600/ 1632 batches | lr 1.25 | ms/batch  2.01 | loss  5.65 | ppl   285.46
2025-10-20 19:48:34.822 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:34.822 | INFO     | __main__:<module>:344 - | end of epoch  15 | time:  3.51s | valid loss  5.66 | valid ppl   287.79
2025-10-20 19:48:34.822 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:48:34.822 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.3125
2025-10-20 19:48:34.858 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:35.276 | INFO     | __main__:train:295 - | epoch  16 |   200/ 1632 batches | lr 0.31 | ms/batch  2.09 | loss  5.67 | ppl   291.30
2025-10-20 19:48:35.680 | INFO     | __main__:train:295 - | epoch  16 |   400/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.65 | ppl   285.19
2025-10-20 19:48:36.100 | INFO     | __main__:train:295 - | epoch  16 |   600/ 1632 batches | lr 0.31 | ms/batch  2.10 | loss  5.65 | ppl   284.50
2025-10-20 19:48:36.504 | INFO     | __main__:train:295 - | epoch  16 |   800/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.65 | ppl   284.28
2025-10-20 19:48:36.908 | INFO     | __main__:train:295 - | epoch  16 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.66 | ppl   286.06
2025-10-20 19:48:37.311 | INFO     | __main__:train:295 - | epoch  16 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   285.06
2025-10-20 19:48:37.716 | INFO     | __main__:train:295 - | epoch  16 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.03 | loss  5.65 | ppl   283.06
2025-10-20 19:48:38.119 | INFO     | __main__:train:295 - | epoch  16 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.65 | ppl   284.15
2025-10-20 19:48:38.377 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:38.377 | INFO     | __main__:<module>:344 - | end of epoch  16 | time:  3.52s | valid loss  5.65 | valid ppl   285.25
2025-10-20 19:48:38.452 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:38.862 | INFO     | __main__:train:295 - | epoch  17 |   200/ 1632 batches | lr 0.31 | ms/batch  2.05 | loss  5.67 | ppl   290.93
2025-10-20 19:48:39.264 | INFO     | __main__:train:295 - | epoch  17 |   400/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   284.97
2025-10-20 19:48:39.667 | INFO     | __main__:train:295 - | epoch  17 |   600/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   284.34
2025-10-20 19:48:40.070 | INFO     | __main__:train:295 - | epoch  17 |   800/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   284.18
2025-10-20 19:48:40.474 | INFO     | __main__:train:295 - | epoch  17 |  1000/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.66 | ppl   285.97
2025-10-20 19:48:40.878 | INFO     | __main__:train:295 - | epoch  17 |  1200/ 1632 batches | lr 0.31 | ms/batch  2.02 | loss  5.65 | ppl   285.02
2025-10-20 19:48:41.280 | INFO     | __main__:train:295 - | epoch  17 |  1400/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   283.04
2025-10-20 19:48:41.683 | INFO     | __main__:train:295 - | epoch  17 |  1600/ 1632 batches | lr 0.31 | ms/batch  2.01 | loss  5.65 | ppl   284.19
2025-10-20 19:48:41.927 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:41.927 | INFO     | __main__:<module>:344 - | end of epoch  17 | time:  3.47s | valid loss  5.65 | valid ppl   285.25
2025-10-20 19:48:41.927 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:48:41.927 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.078125
2025-10-20 19:48:41.959 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:42.385 | INFO     | __main__:train:295 - | epoch  18 |   200/ 1632 batches | lr 0.08 | ms/batch  2.13 | loss  5.67 | ppl   290.86
2025-10-20 19:48:42.797 | INFO     | __main__:train:295 - | epoch  18 |   400/ 1632 batches | lr 0.08 | ms/batch  2.06 | loss  5.65 | ppl   284.90
2025-10-20 19:48:43.202 | INFO     | __main__:train:295 - | epoch  18 |   600/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.65 | ppl   284.24
2025-10-20 19:48:43.617 | INFO     | __main__:train:295 - | epoch  18 |   800/ 1632 batches | lr 0.08 | ms/batch  2.07 | loss  5.65 | ppl   284.02
2025-10-20 19:48:44.023 | INFO     | __main__:train:295 - | epoch  18 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.66 | ppl   285.78
2025-10-20 19:48:44.435 | INFO     | __main__:train:295 - | epoch  18 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.06 | loss  5.65 | ppl   284.72
2025-10-20 19:48:44.840 | INFO     | __main__:train:295 - | epoch  18 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.64 | ppl   282.74
2025-10-20 19:48:45.244 | INFO     | __main__:train:295 - | epoch  18 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   283.75
2025-10-20 19:48:45.488 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:45.489 | INFO     | __main__:<module>:344 - | end of epoch  18 | time:  3.53s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:48:45.548 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:45.959 | INFO     | __main__:train:295 - | epoch  19 |   200/ 1632 batches | lr 0.08 | ms/batch  2.06 | loss  5.67 | ppl   290.72
2025-10-20 19:48:46.364 | INFO     | __main__:train:295 - | epoch  19 |   400/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   284.80
2025-10-20 19:48:46.770 | INFO     | __main__:train:295 - | epoch  19 |   600/ 1632 batches | lr 0.08 | ms/batch  2.03 | loss  5.65 | ppl   284.13
2025-10-20 19:48:47.180 | INFO     | __main__:train:295 - | epoch  19 |   800/ 1632 batches | lr 0.08 | ms/batch  2.05 | loss  5.65 | ppl   283.95
2025-10-20 19:48:47.584 | INFO     | __main__:train:295 - | epoch  19 |  1000/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.66 | ppl   285.73
2025-10-20 19:48:47.989 | INFO     | __main__:train:295 - | epoch  19 |  1200/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   284.70
2025-10-20 19:48:48.394 | INFO     | __main__:train:295 - | epoch  19 |  1400/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.64 | ppl   282.75
2025-10-20 19:48:48.798 | INFO     | __main__:train:295 - | epoch  19 |  1600/ 1632 batches | lr 0.08 | ms/batch  2.02 | loss  5.65 | ppl   283.79
2025-10-20 19:48:49.041 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:49.041 | INFO     | __main__:<module>:344 - | end of epoch  19 | time:  3.49s | valid loss  5.65 | valid ppl   284.95
2025-10-20 19:48:49.041 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:48:49.041 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.01953125
2025-10-20 19:48:49.072 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:49.482 | INFO     | __main__:train:295 - | epoch  20 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   290.72
2025-10-20 19:48:49.888 | INFO     | __main__:train:295 - | epoch  20 |   400/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   284.79
2025-10-20 19:48:50.292 | INFO     | __main__:train:295 - | epoch  20 |   600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.13
2025-10-20 19:48:50.697 | INFO     | __main__:train:295 - | epoch  20 |   800/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   283.93
2025-10-20 19:48:51.100 | INFO     | __main__:train:295 - | epoch  20 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   285.66
2025-10-20 19:48:51.504 | INFO     | __main__:train:295 - | epoch  20 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.61
2025-10-20 19:48:51.912 | INFO     | __main__:train:295 - | epoch  20 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.04 | loss  5.64 | ppl   282.64
2025-10-20 19:48:52.317 | INFO     | __main__:train:295 - | epoch  20 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   283.63
2025-10-20 19:48:52.561 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:52.561 | INFO     | __main__:<module>:344 - | end of epoch  20 | time:  3.49s | valid loss  5.65 | valid ppl   284.89
2025-10-20 19:48:52.637 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:53.048 | INFO     | __main__:train:295 - | epoch  21 |   200/ 1632 batches | lr 0.02 | ms/batch  2.06 | loss  5.67 | ppl   290.67
2025-10-20 19:48:53.452 | INFO     | __main__:train:295 - | epoch  21 |   400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.75
2025-10-20 19:48:53.856 | INFO     | __main__:train:295 - | epoch  21 |   600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.08
2025-10-20 19:48:54.260 | INFO     | __main__:train:295 - | epoch  21 |   800/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   283.89
2025-10-20 19:48:54.662 | INFO     | __main__:train:295 - | epoch  21 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.65 | ppl   285.66
2025-10-20 19:48:55.067 | INFO     | __main__:train:295 - | epoch  21 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.61
2025-10-20 19:48:55.471 | INFO     | __main__:train:295 - | epoch  21 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.64 | ppl   282.64
2025-10-20 19:48:55.885 | INFO     | __main__:train:295 - | epoch  21 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.07 | loss  5.65 | ppl   283.65
2025-10-20 19:48:56.129 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:56.129 | INFO     | __main__:<module>:344 - | end of epoch  21 | time:  3.49s | valid loss  5.65 | valid ppl   284.88
2025-10-20 19:48:56.197 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:56.606 | INFO     | __main__:train:295 - | epoch  22 |   200/ 1632 batches | lr 0.02 | ms/batch  2.05 | loss  5.67 | ppl   290.66
2025-10-20 19:48:57.011 | INFO     | __main__:train:295 - | epoch  22 |   400/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.71
2025-10-20 19:48:57.416 | INFO     | __main__:train:295 - | epoch  22 |   600/ 1632 batches | lr 0.02 | ms/batch  2.03 | loss  5.65 | ppl   284.07
2025-10-20 19:48:57.821 | INFO     | __main__:train:295 - | epoch  22 |   800/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   283.88
2025-10-20 19:48:58.224 | INFO     | __main__:train:295 - | epoch  22 |  1000/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   285.66
2025-10-20 19:48:58.629 | INFO     | __main__:train:295 - | epoch  22 |  1200/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   284.61
2025-10-20 19:48:59.031 | INFO     | __main__:train:295 - | epoch  22 |  1400/ 1632 batches | lr 0.02 | ms/batch  2.01 | loss  5.64 | ppl   282.66
2025-10-20 19:48:59.435 | INFO     | __main__:train:295 - | epoch  22 |  1600/ 1632 batches | lr 0.02 | ms/batch  2.02 | loss  5.65 | ppl   283.66
2025-10-20 19:48:59.678 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:48:59.678 | INFO     | __main__:<module>:344 - | end of epoch  22 | time:  3.48s | valid loss  5.65 | valid ppl   284.88
2025-10-20 19:48:59.678 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:48:59.678 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.0048828125
2025-10-20 19:48:59.710 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:00.123 | INFO     | __main__:train:295 - | epoch  23 |   200/ 1632 batches | lr 0.00 | ms/batch  2.07 | loss  5.67 | ppl   290.66
2025-10-20 19:49:00.528 | INFO     | __main__:train:295 - | epoch  23 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.72
2025-10-20 19:49:00.933 | INFO     | __main__:train:295 - | epoch  23 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.07
2025-10-20 19:49:01.336 | INFO     | __main__:train:295 - | epoch  23 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.88
2025-10-20 19:49:01.740 | INFO     | __main__:train:295 - | epoch  23 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.63
2025-10-20 19:49:02.145 | INFO     | __main__:train:295 - | epoch  23 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.58
2025-10-20 19:49:02.551 | INFO     | __main__:train:295 - | epoch  23 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.64 | ppl   282.61
2025-10-20 19:49:02.958 | INFO     | __main__:train:295 - | epoch  23 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.62
2025-10-20 19:49:03.202 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:03.202 | INFO     | __main__:<module>:344 - | end of epoch  23 | time:  3.49s | valid loss  5.65 | valid ppl   284.87
2025-10-20 19:49:03.260 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:03.670 | INFO     | __main__:train:295 - | epoch  24 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.64
2025-10-20 19:49:04.076 | INFO     | __main__:train:295 - | epoch  24 |   400/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.71
2025-10-20 19:49:04.481 | INFO     | __main__:train:295 - | epoch  24 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.06
2025-10-20 19:49:04.884 | INFO     | __main__:train:295 - | epoch  24 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.87
2025-10-20 19:49:05.288 | INFO     | __main__:train:295 - | epoch  24 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.63
2025-10-20 19:49:05.692 | INFO     | __main__:train:295 - | epoch  24 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.57
2025-10-20 19:49:06.096 | INFO     | __main__:train:295 - | epoch  24 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.64 | ppl   282.62
2025-10-20 19:49:06.500 | INFO     | __main__:train:295 - | epoch  24 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.62
2025-10-20 19:49:06.745 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:06.745 | INFO     | __main__:<module>:344 - | end of epoch  24 | time:  3.49s | valid loss  5.65 | valid ppl   284.87
2025-10-20 19:49:06.824 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:07.234 | INFO     | __main__:train:295 - | epoch  25 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.64
2025-10-20 19:49:07.638 | INFO     | __main__:train:295 - | epoch  25 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.71
2025-10-20 19:49:08.042 | INFO     | __main__:train:295 - | epoch  25 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.06
2025-10-20 19:49:08.446 | INFO     | __main__:train:295 - | epoch  25 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.87
2025-10-20 19:49:08.859 | INFO     | __main__:train:295 - | epoch  25 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.65 | ppl   285.63
2025-10-20 19:49:09.262 | INFO     | __main__:train:295 - | epoch  25 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.58
2025-10-20 19:49:09.665 | INFO     | __main__:train:295 - | epoch  25 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.62
2025-10-20 19:49:10.070 | INFO     | __main__:train:295 - | epoch  25 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.63
2025-10-20 19:49:10.328 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:10.328 | INFO     | __main__:<module>:344 - | end of epoch  25 | time:  3.50s | valid loss  5.65 | valid ppl   284.87
2025-10-20 19:49:10.389 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:10.800 | INFO     | __main__:train:295 - | epoch  26 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.63
2025-10-20 19:49:11.203 | INFO     | __main__:train:295 - | epoch  26 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.70
2025-10-20 19:49:11.605 | INFO     | __main__:train:295 - | epoch  26 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.05
2025-10-20 19:49:12.029 | INFO     | __main__:train:295 - | epoch  26 |   800/ 1632 batches | lr 0.00 | ms/batch  2.12 | loss  5.65 | ppl   283.86
2025-10-20 19:49:12.430 | INFO     | __main__:train:295 - | epoch  26 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.62
2025-10-20 19:49:12.850 | INFO     | __main__:train:295 - | epoch  26 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.10 | loss  5.65 | ppl   284.57
2025-10-20 19:49:13.253 | INFO     | __main__:train:295 - | epoch  26 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.63
2025-10-20 19:49:13.657 | INFO     | __main__:train:295 - | epoch  26 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.65
2025-10-20 19:49:13.906 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:13.907 | INFO     | __main__:<module>:344 - | end of epoch  26 | time:  3.52s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:13.966 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:14.394 | INFO     | __main__:train:295 - | epoch  27 |   200/ 1632 batches | lr 0.00 | ms/batch  2.14 | loss  5.67 | ppl   290.64
2025-10-20 19:49:14.796 | INFO     | __main__:train:295 - | epoch  27 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.68
2025-10-20 19:49:15.198 | INFO     | __main__:train:295 - | epoch  27 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.04
2025-10-20 19:49:15.600 | INFO     | __main__:train:295 - | epoch  27 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.85
2025-10-20 19:49:16.002 | INFO     | __main__:train:295 - | epoch  27 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.62
2025-10-20 19:49:16.405 | INFO     | __main__:train:295 - | epoch  27 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.57
2025-10-20 19:49:16.808 | INFO     | __main__:train:295 - | epoch  27 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.64 | ppl   282.63
2025-10-20 19:49:17.211 | INFO     | __main__:train:295 - | epoch  27 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.64
2025-10-20 19:49:17.456 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:17.456 | INFO     | __main__:<module>:344 - | end of epoch  27 | time:  3.49s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:17.541 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:17.979 | INFO     | __main__:train:295 - | epoch  28 |   200/ 1632 batches | lr 0.00 | ms/batch  2.19 | loss  5.67 | ppl   290.63
2025-10-20 19:49:18.382 | INFO     | __main__:train:295 - | epoch  28 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.68
2025-10-20 19:49:18.787 | INFO     | __main__:train:295 - | epoch  28 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.04
2025-10-20 19:49:19.188 | INFO     | __main__:train:295 - | epoch  28 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.84
2025-10-20 19:49:19.591 | INFO     | __main__:train:295 - | epoch  28 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.62
2025-10-20 19:49:19.994 | INFO     | __main__:train:295 - | epoch  28 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.57
2025-10-20 19:49:20.400 | INFO     | __main__:train:295 - | epoch  28 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.64 | ppl   282.63
2025-10-20 19:49:20.802 | INFO     | __main__:train:295 - | epoch  28 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.65
2025-10-20 19:49:21.044 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:21.044 | INFO     | __main__:<module>:344 - | end of epoch  28 | time:  3.50s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:21.105 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:21.575 | INFO     | __main__:train:295 - | epoch  29 |   200/ 1632 batches | lr 0.00 | ms/batch  2.35 | loss  5.67 | ppl   290.63
2025-10-20 19:49:21.980 | INFO     | __main__:train:295 - | epoch  29 |   400/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.68
2025-10-20 19:49:22.393 | INFO     | __main__:train:295 - | epoch  29 |   600/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.65 | ppl   284.04
2025-10-20 19:49:22.796 | INFO     | __main__:train:295 - | epoch  29 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.85
2025-10-20 19:49:23.198 | INFO     | __main__:train:295 - | epoch  29 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.62
2025-10-20 19:49:23.602 | INFO     | __main__:train:295 - | epoch  29 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.57
2025-10-20 19:49:24.005 | INFO     | __main__:train:295 - | epoch  29 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.64
2025-10-20 19:49:24.407 | INFO     | __main__:train:295 - | epoch  29 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.65
2025-10-20 19:49:24.649 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:24.649 | INFO     | __main__:<module>:344 - | end of epoch  29 | time:  3.54s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:24.708 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:25.124 | INFO     | __main__:train:295 - | epoch  30 |   200/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.67 | ppl   290.62
2025-10-20 19:49:25.526 | INFO     | __main__:train:295 - | epoch  30 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.69
2025-10-20 19:49:25.928 | INFO     | __main__:train:295 - | epoch  30 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.02
2025-10-20 19:49:26.345 | INFO     | __main__:train:295 - | epoch  30 |   800/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.65 | ppl   283.85
2025-10-20 19:49:26.748 | INFO     | __main__:train:295 - | epoch  30 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.62
2025-10-20 19:49:27.152 | INFO     | __main__:train:295 - | epoch  30 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.57
2025-10-20 19:49:27.560 | INFO     | __main__:train:295 - | epoch  30 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.64 | ppl   282.63
2025-10-20 19:49:27.964 | INFO     | __main__:train:295 - | epoch  30 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.65
2025-10-20 19:49:28.208 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:28.209 | INFO     | __main__:<module>:344 - | end of epoch  30 | time:  3.50s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:28.209 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:49:28.209 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.001220703125
2025-10-20 19:49:28.240 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:28.706 | INFO     | __main__:train:295 - | epoch  31 |   200/ 1632 batches | lr 0.00 | ms/batch  2.33 | loss  5.67 | ppl   290.62
2025-10-20 19:49:29.109 | INFO     | __main__:train:295 - | epoch  31 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.67
2025-10-20 19:49:29.512 | INFO     | __main__:train:295 - | epoch  31 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.02
2025-10-20 19:49:29.919 | INFO     | __main__:train:295 - | epoch  31 |   800/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.84
2025-10-20 19:49:30.324 | INFO     | __main__:train:295 - | epoch  31 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.62
2025-10-20 19:49:30.728 | INFO     | __main__:train:295 - | epoch  31 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.56
2025-10-20 19:49:31.133 | INFO     | __main__:train:295 - | epoch  31 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.64 | ppl   282.62
2025-10-20 19:49:31.536 | INFO     | __main__:train:295 - | epoch  31 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.64
2025-10-20 19:49:31.789 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:31.789 | INFO     | __main__:<module>:344 - | end of epoch  31 | time:  3.55s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:31.864 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:32.272 | INFO     | __main__:train:295 - | epoch  32 |   200/ 1632 batches | lr 0.00 | ms/batch  2.04 | loss  5.67 | ppl   290.61
2025-10-20 19:49:32.682 | INFO     | __main__:train:295 - | epoch  32 |   400/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.65 | ppl   284.67
2025-10-20 19:49:33.085 | INFO     | __main__:train:295 - | epoch  32 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.03
2025-10-20 19:49:33.489 | INFO     | __main__:train:295 - | epoch  32 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.84
2025-10-20 19:49:33.893 | INFO     | __main__:train:295 - | epoch  32 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.61
2025-10-20 19:49:34.297 | INFO     | __main__:train:295 - | epoch  32 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.56
2025-10-20 19:49:34.699 | INFO     | __main__:train:295 - | epoch  32 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.63
2025-10-20 19:49:35.102 | INFO     | __main__:train:295 - | epoch  32 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.64
2025-10-20 19:49:35.347 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:35.347 | INFO     | __main__:<module>:344 - | end of epoch  32 | time:  3.48s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:35.408 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:35.828 | INFO     | __main__:train:295 - | epoch  33 |   200/ 1632 batches | lr 0.00 | ms/batch  2.10 | loss  5.67 | ppl   290.61
2025-10-20 19:49:36.230 | INFO     | __main__:train:295 - | epoch  33 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.67
2025-10-20 19:49:36.634 | INFO     | __main__:train:295 - | epoch  33 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.03
2025-10-20 19:49:37.037 | INFO     | __main__:train:295 - | epoch  33 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.84
2025-10-20 19:49:37.466 | INFO     | __main__:train:295 - | epoch  33 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.15 | loss  5.65 | ppl   285.61
2025-10-20 19:49:37.872 | INFO     | __main__:train:295 - | epoch  33 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.56
2025-10-20 19:49:38.274 | INFO     | __main__:train:295 - | epoch  33 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.62
2025-10-20 19:49:38.680 | INFO     | __main__:train:295 - | epoch  33 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.63
2025-10-20 19:49:38.923 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:38.923 | INFO     | __main__:<module>:344 - | end of epoch  33 | time:  3.51s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:38.984 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:39.395 | INFO     | __main__:train:295 - | epoch  34 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.62
2025-10-20 19:49:39.799 | INFO     | __main__:train:295 - | epoch  34 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.67
2025-10-20 19:49:40.203 | INFO     | __main__:train:295 - | epoch  34 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.03
2025-10-20 19:49:40.606 | INFO     | __main__:train:295 - | epoch  34 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.83
2025-10-20 19:49:41.010 | INFO     | __main__:train:295 - | epoch  34 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.61
2025-10-20 19:49:41.415 | INFO     | __main__:train:295 - | epoch  34 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.57
2025-10-20 19:49:41.820 | INFO     | __main__:train:295 - | epoch  34 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.64 | ppl   282.62
2025-10-20 19:49:42.222 | INFO     | __main__:train:295 - | epoch  34 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.64
2025-10-20 19:49:42.473 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:42.473 | INFO     | __main__:<module>:344 - | end of epoch  34 | time:  3.49s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:42.535 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:42.952 | INFO     | __main__:train:295 - | epoch  35 |   200/ 1632 batches | lr 0.00 | ms/batch  2.08 | loss  5.67 | ppl   290.61
2025-10-20 19:49:43.357 | INFO     | __main__:train:295 - | epoch  35 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.66
2025-10-20 19:49:43.800 | INFO     | __main__:train:295 - | epoch  35 |   600/ 1632 batches | lr 0.00 | ms/batch  2.22 | loss  5.65 | ppl   284.03
2025-10-20 19:49:44.206 | INFO     | __main__:train:295 - | epoch  35 |   800/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.83
2025-10-20 19:49:44.609 | INFO     | __main__:train:295 - | epoch  35 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.61
2025-10-20 19:49:45.013 | INFO     | __main__:train:295 - | epoch  35 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.56
2025-10-20 19:49:45.425 | INFO     | __main__:train:295 - | epoch  35 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.64 | ppl   282.63
2025-10-20 19:49:45.829 | INFO     | __main__:train:295 - | epoch  35 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.63
2025-10-20 19:49:46.074 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:46.074 | INFO     | __main__:<module>:344 - | end of epoch  35 | time:  3.54s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:46.149 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:46.560 | INFO     | __main__:train:295 - | epoch  36 |   200/ 1632 batches | lr 0.00 | ms/batch  2.05 | loss  5.67 | ppl   290.61
2025-10-20 19:49:46.966 | INFO     | __main__:train:295 - | epoch  36 |   400/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   284.67
2025-10-20 19:49:47.370 | INFO     | __main__:train:295 - | epoch  36 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.02
2025-10-20 19:49:47.772 | INFO     | __main__:train:295 - | epoch  36 |   800/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.83
2025-10-20 19:49:48.175 | INFO     | __main__:train:295 - | epoch  36 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   285.61
2025-10-20 19:49:48.578 | INFO     | __main__:train:295 - | epoch  36 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.56
2025-10-20 19:49:48.980 | INFO     | __main__:train:295 - | epoch  36 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.63
2025-10-20 19:49:49.383 | INFO     | __main__:train:295 - | epoch  36 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   283.65
2025-10-20 19:49:49.626 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:49.627 | INFO     | __main__:<module>:344 - | end of epoch  36 | time:  3.48s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:49.682 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:50.101 | INFO     | __main__:train:295 - | epoch  37 |   200/ 1632 batches | lr 0.00 | ms/batch  2.09 | loss  5.67 | ppl   290.61
2025-10-20 19:49:50.503 | INFO     | __main__:train:295 - | epoch  37 |   400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.68
2025-10-20 19:49:50.906 | INFO     | __main__:train:295 - | epoch  37 |   600/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.02
2025-10-20 19:49:51.312 | INFO     | __main__:train:295 - | epoch  37 |   800/ 1632 batches | lr 0.00 | ms/batch  2.03 | loss  5.65 | ppl   283.84
2025-10-20 19:49:51.716 | INFO     | __main__:train:295 - | epoch  37 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.61
2025-10-20 19:49:52.120 | INFO     | __main__:train:295 - | epoch  37 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.56
2025-10-20 19:49:52.524 | INFO     | __main__:train:295 - | epoch  37 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.64 | ppl   282.62
2025-10-20 19:49:52.936 | INFO     | __main__:train:295 - | epoch  37 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.06 | loss  5.65 | ppl   283.64
2025-10-20 19:49:53.178 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:53.178 | INFO     | __main__:<module>:344 - | end of epoch  37 | time:  3.50s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:53.178 | INFO     | __main__:<module>:367 - | epochs since loss improved: 1
2025-10-20 19:49:53.178 | INFO     | __main__:<module>:368 - | reducing learning rate to 0.00030517578125
2025-10-20 19:49:53.210 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:53.624 | INFO     | __main__:train:295 - | epoch  38 |   200/ 1632 batches | lr 0.00 | ms/batch  2.07 | loss  5.67 | ppl   290.62
2025-10-20 19:49:54.029 | INFO     | __main__:train:295 - | epoch  38 |   400/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.67
2025-10-20 19:49:54.432 | INFO     | __main__:train:295 - | epoch  38 |   600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   284.03
2025-10-20 19:49:54.836 | INFO     | __main__:train:295 - | epoch  38 |   800/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.83
2025-10-20 19:49:55.240 | INFO     | __main__:train:295 - | epoch  38 |  1000/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   285.61
2025-10-20 19:49:55.643 | INFO     | __main__:train:295 - | epoch  38 |  1200/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.65 | ppl   284.56
2025-10-20 19:49:56.045 | INFO     | __main__:train:295 - | epoch  38 |  1400/ 1632 batches | lr 0.00 | ms/batch  2.01 | loss  5.64 | ppl   282.63
2025-10-20 19:49:56.449 | INFO     | __main__:train:295 - | epoch  38 |  1600/ 1632 batches | lr 0.00 | ms/batch  2.02 | loss  5.65 | ppl   283.64
2025-10-20 19:49:56.696 | INFO     | __main__:<module>:343 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:56.696 | INFO     | __main__:<module>:344 - | end of epoch  38 | time:  3.49s | valid loss  5.65 | valid ppl   284.86
2025-10-20 19:49:56.696 | INFO     | __main__:<module>:367 - | epochs since loss improved: 2
2025-10-20 19:49:56.696 | INFO     | __main__:<module>:368 - | reducing learning rate to 7.62939453125e-05
2025-10-20 19:49:56.732 | INFO     | __main__:<module>:374 - -----------------------------------------------------------------------------------------
2025-10-20 19:49:56.959 | INFO     | __main__:<module>:390 - =========================================================================================
2025-10-20 19:49:56.959 | INFO     | __main__:<module>:391 - | End of training | test loss  5.66 | test ppl   286.39
2025-10-20 19:49:56.959 | INFO     | __main__:<module>:396 - =========================================================================================
2025-10-21 18:16:42.783 | INFO     | __main__:<module>:76 - Using GPU ID 0
2025-10-21 18:16:42.899 | INFO     | __main__:<module>:82 - Loading data
2025-10-21 18:16:42.900 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-21 18:16:51.975 | INFO     | __main__:<module>:76 - Using GPU ID 0
2025-10-21 18:16:52.088 | INFO     | __main__:<module>:82 - Loading data
2025-10-21 18:16:52.088 | INFO     | corpus:__init__:69 - Initializing corpus for experiment childes_exp1
2025-10-21 18:16:55.758 | INFO     | corpus:__init__:86 - Loaded dictionary from data/wikipedia/train_dict_42ccc5f4.cached
2025-10-21 18:16:55.758 | INFO     | corpus:tokenize:146 - Tokenizing data/wikipedia/train.txt.original...
2025-10-21 18:17:00.217 | INFO     | corpus:tokenize:146 - Tokenizing data/wikipedia/valid.txt.original...
2025-10-21 18:17:00.874 | INFO     | corpus:tokenize:146 - Tokenizing data/wikipedia/test.txt.original...
2025-10-21 18:17:01.540 | INFO     | corpus:__init__:104 - Done tokenizing.
2025-10-21 18:17:01.540 | INFO     | __main__:<module>:88 - ( 9.45 )
2025-10-21 18:17:01.540 | INFO     | __main__:<module>:90 - Vocab size %d
2025-10-21 18:17:01.540 | INFO     | __main__:<module>:93 - Batchifying..
2025-10-21 18:17:03.243 | INFO     | __main__:<module>:128 - Building the model
2025-10-21 18:17:08.515 | INFO     | __main__:<module>:319 - Running Transformer with args: {'data': 'data/wikipedia', 'load': None, 'finetune': False, 'model': 'Transformer', 'emsize': 200, 'nhid': 200, 'nlayers': 2, 'dropout': 0.2, 'tied': False, 'nhead': 2, 'lr': 20, 'clip': 0.25, 'patience': 2, 'batch_size': 20, 'bptt': 35, 'seed': 1111, 'cuda': True, 'log_interval': 200, 'save': 'model.pt', 'log': 'log.txt', 'experiment_id': 'childes_exp1', 'gpu_id': None}
2025-10-21 18:17:08.515 | INFO     | __main__:<module>:321 - Transformer id: 02448272
